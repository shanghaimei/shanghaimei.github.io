<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python的requests库]]></title>
    <url>%2F2018%2F09%2F18%2Fpython%E7%9A%84requests%E5%BA%93%2F</url>
    <content type="text"><![CDATA[requests各种请求方式 1234567891011121314151617#版本号In [46]: requests.__version__Out[46]: '2.19.1'In [6]: import requestsIn [7]: r = requests.get('https://api.github.com/events')In [8]: r = requests.post('http://httpbin.org/post', data = &#123;'key':'value'&#125;)In [9]: r = requests.put('http://httpbin.org/put', data = &#123;'key':'value'&#125;)In [10]: r = requests.delete('http://httpbin.org/delete')In [11]: r = requests.head('http://httpbin.org/get')In [12]: r = requests.options('http://httpbin.org/get') url拼接 123456In [13]: payload = &#123;'key1':'value1','v2':'value2'&#125;In [14]: r = requests.get("http://httpbin.org/get", params=payload)In [15]: r.urlOut[15]: 'http://httpbin.org/get?key1=value1&amp;v2=value2' requests响应内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172In [1]: import requestsIn [2]: r = requests.get("http://bj.meituan.com/meishi/")In [3]: r.status_codeOut[3]: 200In [4]: r.encodingOut[4]: 'utf-8'In [5]: r.headersOut[5]: &#123;'Server': 'Tengine', 'Date': 'Thu, 12 Jul 2018 09:50:36 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'X-Powered-By': 'dx-web-meishife-pcweb04.dx.sankuai.com_production', 'Set-Cookie': 'client-id=2247b634-52ff-4a27-a0a9-01b1810e6d9f; path=/; expires=Fri, 13 Jul 2018 09:50:36 GMT; httponly, uuid=9b6cad4c-90fa-4f51-a59c-5f4f37cd4464; path=/; domain=meituan.com; httponly', 'Cache-Control': 'no-cache', 'Vary': 'Accept-Encoding', 'Content-Encoding': 'gzip'&#125;#请求头大小写不敏感可以不区分大小写调用,例:r.headers.get('server')In [6]: r.text#内容太多In [47]: r = requests.get('https://api.github.com/events')In [48]: r.json()#示例返回2条内容[&#123;'id': '7959832918', 'type': 'PushEvent', 'actor': &#123;'id': 7868421, 'login': 'whitestone8214', 'display_login': 'whitestone8214', 'gravatar_id': '', 'url': 'https://api.github.com/users/whitestone8214', 'avatar_url': 'https://avatars.githubusercontent.com/u/7868421?'&#125;, 'repo': &#123;'id': 139670300, 'name': 'whitestone8214/Crawler', 'url': 'https://api.github.com/repos/whitestone8214/Crawler'&#125;, 'payload': &#123;'push_id': 2716420119, 'size': 1, 'distinct_size': 1, 'ref': 'refs/heads/master', 'head': 'd178c8282b826cf360e3e4656d0258aedaaace36', 'before': '6c08e2c6f66243c1003df07a80af10e337def37b', 'commits': [&#123;'sha': 'd178c8282b826cf360e3e4656d0258aedaaace36', 'author': &#123;'email': 'whitestone8214@openmailbox.org', 'name': 'Minho Jo'&#125;, 'message': "#2: whiteline.js 0.2.1 (과 그에 따른 마이그레이션); 입력란 크기 조절; 다시 그린 툴바 아이콘(일단은 툴바 쪽만); 컨텍스트 메뉴 '텍스트 에디터로 열기'; 기타 등등", 'distinct': True, 'url': 'https://api.github.com/repos/whitestone8214/Crawler/commits/d178c8282b826cf360e3e4656d0258aedaaace36'&#125;]&#125;, 'public': True, 'created_at': '2018-07-13T03:27:17Z'&#125;, &#123;'id': '7959832917', 'type': 'WatchEvent', 'actor': &#123;'id': 5679265, 'login': 'LFH104', 'display_login': 'LFH104', 'gravatar_id': '', 'url': 'https://api.github.com/users/LFH104', 'avatar_url': 'https://avatars.githubusercontent.com/u/5679265?'&#125;, 'repo': &#123;'id': 129860458, 'name': 'phobal/ivideo', 'url': 'https://api.github.com/repos/phobal/ivideo'&#125;, 'payload': &#123;'action': 'started'&#125;, 'public': True, 'created_at': '2018-07-13T03:27:17Z'&#125;]In [48]: r = requests.get('https://api.github.com/events', stream=True)ln [50]: r.rawOut[50]: &lt;urllib3.response.HTTPResponse at 0x7fe0a51a4278&gt;In [51]: r.raw.read(10)Out[51]: b'\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03'In [74]: r = requests.get('http://github.com')In [75]: r.urlOut[75]: 'https://github.com/'In [76]: r.historyOut[76]: [&lt;Response [301]&gt;] post请求form表单 12345678910111213#字典形式In [13]: payload = &#123;'key1':'value1','v2':'value2'&#125;In [16]: r = requests.post("http://httpbin.org/post", data=payload)In [17]: r.textOut[17]: '&#123;"args":&#123;&#125;,"data":"","files":&#123;&#125;,"form":&#123;"key1":"value1","v2":"value2"&#125;,"headers":&#123;"Accept":"*/*","Accept-Encoding":"gzip, deflate","Connection":"close","Content-Length":"21","Content-Type":"application/x-www-form-urlencoded","Host":"httpbin.org","User-Agent":"python-requests/2.18.4"&#125;,"json":null,"origin":"47.90.49.89","url":"http://httpbin.org/post"&#125;\n'#元组形式In [18]: payload = (('key1', 'value1'), ('key1', 'value2'))In [19]: r = requests.post("http://httpbin.org/post", data=payload)In [20]: r.textOut[20]: '&#123;"args":&#123;&#125;,"data":"","files":&#123;&#125;,"form":&#123;"key1":["value1","value2"]&#125;,"headers":&#123;"Accept":"*/*","Accept-Encoding":"gzip, deflate","Connection":"close","Content-Length":"23","Content-Type":"application/x-www-form-urlencoded","Host":"httpbin.org","User-Agent":"python-requests/2.18.4"&#125;,"json":null,"origin":"47.90.49.89","url":"http://httpbin.org/post"&#125;\n' 自定义请求头 123456789101112131415161718192021222324252627282930In [52]: url = 'https://api.github.com/some/endpoint'In [53]: headers = &#123;'user-agent': 'my-app/0.0.1'&#125;In [54]: r = requests.get(url, headers=headers)栗子:import requestsimport jsonfrom datetime import date,datetimeimport time# 发送群消息url = "https://api.telegram.org/bot"headers = &#123;'Content-Type': 'application/json'&#125;data = &#123; "chat_id": -12345, "text": "**hi**", "reply_markup": &#123; "inline_keyboard": [[&#123; "text":"google", "url":"www.google.com" &#125;]] &#125;, "parse_mode":"Markdown" &#125;content = requests.post(url,headers=headers,data=json.dumps(data))data =json.loads(content.text)print(data) 自定义cookie 123456789101112131415161718192021222324252627282930In [61]: url = 'http://httpbin.org/cookies'In [62]: cookies = dict(cookies_are='working')In [63]: r = requests.get(url, cookies=cookies)In [64]: r.textOut[64]: '&#123;"cookies":&#123;"cookies_are":"working"&#125;&#125;\n'In [65]: jar = requests.cookies.RequestsCookieJar()In [66]: jar.set('tasty_cookie', 'yum', domain='httpbin.org', path='/cookies')Out[66]: Cookie(version=0, name='tasty_cookie', value='yum', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/cookies', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest=&#123;'HttpOnly': None&#125;, rfc2109=False)In [67]: jar.set('gross_cookie', 'blech', domain='httpbin.org', path='/elsewhere ')Out[67]: Cookie(version=0, name='gross_cookie', value='blech', port=None, port_specified=False, domain='httpbin.org', domain_specified=True, domain_initial_dot=False, path='/elsewhere', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest=&#123;'HttpOnly': None&#125;, rfc2109=False)In [68]: url = 'http://httpbin.org/cookies'In [69]: r = requests.get(url, cookies=jar)In [70]: r.textOut[70]: '&#123;"cookies":&#123;"tasty_cookie":"yum"&#125;&#125;\n'In [71]: url = 'http://httpbin.org/elsewhere'In [72]: r = requests.get(url, cookies=jar)In [73]: r.textOut[73]: '&lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN"&gt;\n&lt;title&gt;404 Not Found&lt;/title&gt;\n&lt;h1&gt;Not Found&lt;/h1&gt;\n&lt;p&gt;The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.&lt;/p&gt;\n' requests爬虫小栗子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import requestsimport jsonimport redisfrom datetime import date,datetimeimport timer = redis.StrictRedis('localhost',6379,decode_responses=True,db = 3)class JsonExtendEncoder(json.JSONEncoder): """ This class provide an extension to json serialization for datetime/date. """ def default(self, obj): """ provide a interface for datetime/date """ if isinstance(obj, datetime): return obj.strftime('%Y-%m-%d %H:%M:%S') elif isinstance(obj, date): return obj.strftime('%Y-%m-%d') else: return json.JSONEncoder.default(self, obj)i = 0while True: p = r.pipeline() url = "https://api.schail.com/v3/ticker/summary?type=0&amp;sort=1&amp;offset=0&amp;limit=100&amp;top=0" time.sleep(2) content = requests.get(url) data =json.loads(content.text) data_dict = &#123;&#125; data = data.get('data') data_dict['data'] = data current_time = datetime.now() data_dict['current_time'] = current_time # print(data_dict) exchange_list = [] for tid_dict in data.get('summaryList'): pair_url = "https://api.schail.com/v1/ticker/exchange?tickerId=%s&amp;offset=0&amp;limit=50"%tid_dict['tickerId'] pair_content = requests.get(pair_url) pair_data = json.loads(pair_content.text) exchange_dict = &#123;&#125; exchange_dict['data'] = pair_data['data'] current_time = datetime.now() exchange_dict['current_time'] = current_time exchange_list.append(exchange_dict) data_dict['exchange_list'] = exchange_list print(data_dict) i += 1 p.execute() r.zadd("tokenclubdata", i,json.dumps(data_dict,ensure_ascii=False,cls=JsonExtendEncoder))# https://api.schail.com/v1/ticker/exchange?tickerId=bitcoin&amp;offset=0&amp;limit=50# https://api.schail.com/v1/ticker/exchange?tickerId=ethereum&amp;offset=0&amp;limit=50]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Selenium使用]]></title>
    <url>%2F2018%2F09%2F15%2FSelenium%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[自动化测试工具，支持多种浏览器。爬虫中主要用来解决javaScrapt渲染的问题。安装：pip install selenium,brew install chromedriver 基本使用 12345678910111213141516171819from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.support.wait import WebDriverWaitbrowser = webdriver.Chrome()try: browser.get('http://www.baidu.com') input = browser.find_element_by_id('kw') input.send_keys('python') input.send_keys(Keys.ENTER) wait = WebDriverWait(browser, 10) wait.until(EC.presence_of_element_located((By.ID, 'content_left'))) print(browser.current_url) print(browser.get_cookies()) print(browser.page_source)finally: browser.close() 声明浏览器对象 123456from selenium import webdriverbrowser = webdriver.Chrome()browser = webdriver.Firefox()browser = webdriver.Edge()browser = webdriver.PhantomJS()browser = webdriver.Safari() 访问页面 12345from selenium import webdriverbrowser = webdriver.Chrome()browser.get('http://www.taobao.com')print(browser.page_source)browser.close() 单个元素 12345678from selenium import webdriverbrowser = webdriver.Chrome()browser.get('http://www.taobao.com')input_first = browser.find_element_by_id('q')input_second = browser.find_element_by_css_selector('#q')input_third = browser.find_element_by_xpath('//*[@id="q"]')print(input_first, input_second, input_third)browser.close() find_element_by_namefind_element_by_xpathfind_element_by_link_textfind_element_by_partial_link_textfind_element_by_tag_namefind_element_by_class_namefind_element_by_css_selector 多个元素 12345678from selenium import webdriverfrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('http://www.taobao.com')lis1 = browser.find_elements_by_css_selector('.service-bd li')lis2 = browser.find_elements(By.CSS_SELECTOR, '.service-bd li')print(lis1, lis2)browser.close() find_elements_by_namefind_elements_by_xpathfind_elements_by_link_textfind_elements_by_partial_link_textfind_elements_by_tag_namefind_elements_by_class_namefind_elements_by_css_selector 元素交互操作 12345678910111213from selenium import webdriverimport timefrom selenium.webdriver.common.by import Bybrowser = webdriver.Chrome()browser.get('http://www.taobao.com')input = browser.find_element_by_id('q')#找到id为q的input文本框input.send_keys('iphone')#文本框输入iphone搜索time.sleep(1)input.clear()#把文本框清空input.send_keys('ipad')button = browser.find_element_by_class_name('btn-search')button.click()#模拟点击搜索按钮#现在有登陆验证了。。。 更多内容查看https://selenium-python-zh.readthedocs.io/en/latest/index.html 元素交互动作 1234567891011from selenium import webdriverfrom selenium.webdriver import ActionChainsbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')source = browser.find_element_by_css_selector('#draggable')target = browser.find_element_by_css_selector('#droppable')actions = ActionChains(browser)actions.drag_and_drop(source, target)actions.perform() 执行javascrapt 12345from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')browser.execute_script('alert("To Botton")') 获取属性值 123456from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')logo = browser.find_element_by_id('zh-top-link-logo')print(logo)print(logo.get_attribute('class')) 获取文本值 12345from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input.text) 获取ID，位置，标签名，大小 12345678from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input.text)print(input.location)print(input.tag_name)print(input.size) Frame 123456789101112131415161718import timefrom selenium import webdriverfrom selenium.common.exceptions import NoSuchElementExceptionbrowser = webdriver.Chrome()url = 'http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable'browser.get(url)browser.switch_to.frame('iframeResult')source = browser.find_element_by_css_selector('#draggable')print(source)try: logo = browser.find_element_by_class_name('logo')except NoSuchElementException: print('No logo')browser.switch_to.parent_frame()logo = browser.find_element_by_class_name('logo')print(logo)print(logo.text) 等待隐式等待 123456from selenium import webdriverbrowser = webdriver.Chrome()browser.implicitly_wait(10)browser.get('https://www.zhihu.com/explore')input = browser.find_element_by_class_name('zu-top-add-question')print(input) 显示等待 12345678910from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.get('https://www.taobao.com/')wait = WebDriverWait(browser,10)input = wait.until(EC.presence_of_element_located((By.ID,'q')))button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,'btn-search')))print(input,button) title_is 标题是某内容title_contains 标题包含某内容presence_of_element_located 元素加载出，传入定位元组，如（By.ID, ‘p’）visibility_of_element_located 元素可见，传入定位元组visibility_of 可见，传入元素对象presence_of_all_element_located 所有元素加载出text_to_be_present_in_element 某个元素文本包含某文字text_to_be_present_in_element_value 某个元素值包含某文字frame_to_be_available_and_switch_to_it frame加载并切换invisibility_of_element_located 元素不可见element_to_be_clickable 元素可点击staieness_of 判断一个元素是否仍在DOM.可判断页面是否已经刷新element_to_be_selected 元素可选择，传元素对象element_located_to_be_selected 元素可选择，传入定位元素element_selection_state_to_be 传入元素对象以及状态，相等返回True, 否则返回falseelement_located_selection_state_to_be 传入定位元组以及状态，相等返回True,否则返回falsealert_is_pressent 是否出现alert 前进后退 12345678910from selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')browser.get('https://www.taobao.com')browser.get('https://www.python.org')browser.back()time.sleep(1)browser.forward()browser.close() cookies 12345678910from selenium import webdriverimport timebrowser = webdriver.Chrome()browser.get('https://www.zhihu.com/explore')print(browser.get_cookies())browser.add_cookie( &#123;'name': 'name', 'domain': 'www.zhihu.com', 'value': 'germey'&#125;)print(browser.get_cookies())browser.delete_all_cookies()print(browser.get_cookies()) 选项卡管理 1234567891011import timefrom selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.execute_script('window.open()')print(browser.window_handles)browser.switch_to_window(browser.window_handles[1])browser.get('https://www.taobao.com')time.sleep(1)browser.switch_to_window(browser.window_handles[0])browser.get('https://python.org') 异常处理 12345from selenium import webdriverbrowser = webdriver.Chrome()browser.get('https://www.baidu.com')browser.find_element_by_id('hello')#会报错selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: &#123;"method":"id","selector":"hello"&#125; 12345678910111213from selenium import webdriverfrom selenium.common.exceptions import TimeoutException, NoSuchElementExceptionbrowser = webdriver.Chrome()try: browser.get('https://www.baidu.com')except TimeoutException: print('Time Out')try: browser.find_element_by_id('hello')except NoSuchElementException: print('No Element')finally: browser.close()]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pyquery使用]]></title>
    <url>%2F2018%2F09%2F12%2Fpyquery%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[初始化字符串初始化1234567891011121314html = '''&lt;div&gt; &lt;ul&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)print(doc('li')) &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;URL初始化123from pyquery import PyQuery as pqdoc = pq(url='http://www.baidu.com')print(doc('head')) &lt;head&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;/&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=Edge&quot;/&gt;&lt;meta content=&quot;always&quot; name=&quot;referrer&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&quot;/&gt;&lt;title&gt;ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é&lt;/title&gt;&lt;/head&gt; 文件初始化123from pyquery import PyQuery as pqdoc = pq(filename='demo.html')print(doc('li')) &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;基本CSS选择器1234567891011121314html = '''&lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)print(doc('#container .list li')) &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;查找元素子元素12345678910111213141516171819html = '''&lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)items = doc('.list')print(type(items))print(items)lis = items.find('li')print(type(lis))print(lis) &lt;class &apos;pyquery.pyquery.PyQuery&apos;&gt; &lt;ul class=&quot;list&quot;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;class &apos;pyquery.pyquery.PyQuery&apos;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;123lis = items.children()print(type(lis))print(lis) &lt;class &apos;pyquery.pyquery.PyQuery&apos;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;12lis = items.children('.active')print(lis) &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;父元素1234567891011121314151617html = '''&lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)items = doc('.list')container = items.parent()print(type(container))print(container) &lt;class &apos;pyquery.pyquery.PyQuery&apos;&gt; &lt;div id=&quot;container&quot;&gt; &lt;ul class=&quot;list&quot;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;12345678910111213141516171819html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)items = doc('.list')parents = items.parents()print(type(parents))print(parents) &lt;class &apos;pyquery.pyquery.PyQuery&apos;&gt; &lt;div class=&quot;wrap&quot;&gt; &lt;div id=&quot;container&quot;&gt; &lt;ul class=&quot;list&quot;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;&lt;div id=&quot;container&quot;&gt; &lt;ul class=&quot;list&quot;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;12parent = items.parents('.wrap')print(parent) &lt;div class=&quot;wrap&quot;&gt; &lt;div id=&quot;container&quot;&gt; &lt;ul class=&quot;list&quot;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;兄弟元素1234567891011121314151617html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.list .item-0.active')print(li.siblings()) &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;1234567891011121314151617html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.list .item-0.active')print(li.siblings('.active')) &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt;遍历单个元素1234567891011121314151617html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.item-0.active')print(li) &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;12345678910111213141516171819html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)lis = doc('li').items()print(type(lis))for li in lis: print(li) &lt;class &apos;generator&apos;&gt; &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt;获取信息获取属性12345678910111213141516171819html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)a = doc('.item-0.active a')print(a)print(a.attr('href'))print(a.attr.href) &lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt; link3.html link3.html获取文本123456789101112131415161718html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)a = doc('.item-0.active a')print(a)print(a.text()) &lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt; third item获取HTML123456789101112131415161718html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.item-0.active')print(li)print(li.html()) &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;DOM操作addClass、removeClass123456789101112131415161718192021html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.item-0.active')print(li)li.removeClass('active')print(li)li.addClass('active')print(li) &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;attr、css123456789101112131415161718192021html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('.item-0.active')print(li)li.attr('name', 'link')print(li)li.css('font-size', '14px')print(li) &lt;li class=&quot;item-0 active&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot; name=&quot;link&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0 active&quot; name=&quot;link&quot; style=&quot;font-size: 14px&quot;&gt;&lt;a href=&quot;link3.html&quot;&gt;&lt;span class=&quot;bold&quot;&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;remove123456789101112html = '''&lt;div class="wrap"&gt; Hello, World &lt;p&gt;This is a paragraph.&lt;/p&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)wrap = doc('.wrap')print(wrap.text())wrap.find('p').remove()print(wrap.text()) Hello, World This is a paragraph. Hello, World其他DOM方法http://pyquery.readthedocs.io/en/latest/api.html 伪类选择器123456789101112131415161718192021222324252627html = '''&lt;div class="wrap"&gt; &lt;div id="container"&gt; &lt;ul class="list"&gt; &lt;li class="item-0"&gt;first item&lt;/li&gt; &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0 active"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li class="item-1 active"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt;'''from pyquery import PyQuery as pqdoc = pq(html)li = doc('li:first-child')print(li)li = doc('li:last-child')print(li)li = doc('li:nth-child(2)')print(li)li = doc('li:gt(2)')print(li)li = doc('li:nth-child(2n)')print(li)li = doc('li:contains(second)')print(li) &lt;li class=&quot;item-0&quot;&gt;first item&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-0&quot;&gt;&lt;a href=&quot;link5.html&quot;&gt;fifth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1 active&quot;&gt;&lt;a href=&quot;link4.html&quot;&gt;fourth item&lt;/a&gt;&lt;/li&gt; &lt;li class=&quot;item-1&quot;&gt;&lt;a href=&quot;link2.html&quot;&gt;second item&lt;/a&gt;&lt;/li&gt;更多CSS选择器可以查看http://www.w3school.com.cn/css/index.asp 官方文档http://pyquery.readthedocs.io/]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Beautiful soup使用]]></title>
    <url>%2F2018%2F09%2F11%2FBeautifulsoup%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[解析器 使用方法 优势 劣势 Python标准库 BeautifulSoup(markup, “html.parser”) Python的内置标准库、执行速度适中、文档容错能力强 Python 2.7.3及Python 3.2.2之前的版本文档容错能力差 lxml HTML解析器 BeautifulSoup(markup, “lxml”) 速度快、文档容错能力强 需要安装C语言库 lxml XML解析器 BeautifulSoup(markup, “xml”) 速度快、唯一支持XML的解析器 需要安装C语言库 html5lib BeautifulSoup(markup, “html5lib”) 最好的容错性、以浏览器的方式解析文档、生成HTML5格式的文档 速度慢、不依赖外部扩展 #### 提取标签中的字符串 1from bs4 import BeautifulSoup 1soup = BeautifulSoup('&lt;p&gt;Hello&lt;/p&gt;','lxml') 1print(soup.p.string) Hello基本用法 1234567891011html = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class="story"&gt;...&lt;/p&gt;""" 1from bs4 import BeautifulSoup 1soup = BeautifulSoup(html,'lxml') 1soup.prettify() &apos;&lt;html&gt;\n &lt;head&gt;\n &lt;title&gt;\n The Dormouse\&apos;s story\n &lt;/title&gt;\n &lt;/head&gt;\n &lt;body&gt;\n &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;\n &lt;b&gt;\n The Dormouse\&apos;s story\n &lt;/b&gt;\n &lt;/p&gt;\n &lt;p class=&quot;story&quot;&gt;\n Once upon a time there were three little sisters; and their names were\n &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;\n &lt;!-- Elsie --&gt;\n &lt;/a&gt;\n ,\n &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;\n Lacie\n &lt;/a&gt;\n and\n &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;\n Tillie\n &lt;/a&gt;\n ;\nand they lived at the bottom of a well.\n &lt;/p&gt;\n &lt;p class=&quot;story&quot;&gt;\n ...\n &lt;/p&gt;\n &lt;/body&gt;\n&lt;/html&gt;&apos;1soup.title.string &quot;The Dormouse&apos;s story&quot;节点选择器选择元素 1soup.title &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;1type(soup.title) bs4.element.Tag1soup.title.string &quot;The Dormouse&apos;s story&quot;1soup.head &lt;head&gt;&lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;&lt;/head&gt;1soup.p &lt;p class=&quot;title&quot; name=&quot;dromouse&quot;&gt;&lt;b&gt;The Dormouse&apos;s story&lt;/b&gt;&lt;/p&gt;提取信息 1soup.title.name &apos;title&apos;获取属性 1soup.p.attrs {&apos;class&apos;: [&apos;title&apos;], &apos;name&apos;: &apos;dromouse&apos;}1soup.p.attrs['name'] &apos;dromouse&apos;1soup.p['name'] &apos;dromouse&apos;1soup.p['class'] [&apos;title&apos;]获取内容 1soup.p.string &quot;The Dormouse&apos;s story&quot;嵌套选择 1234html = """&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;""" 1from bs4 import BeautifulSoup 1soup = BeautifulSoup(html,'lxml') 1soup.head.title &lt;title&gt;The Dormouse&apos;s story&lt;/title&gt;1type(soup.head.title) bs4.element.Tag1soup.head.title.string &quot;The Dormouse&apos;s story&quot;关联选择 子节点和子孙节点 123456789101112131415161718html = """&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and &lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class="story"&gt;...&lt;/p&gt;""" 1from bs4 import BeautifulSoup 1soup = BeautifulSoup(html,'lxml') 1soup.p.children &lt;list_iterator at 0x107d82518&gt;12for i ,child in enumerate(soup.p.children): print(i,child) 0 Once upon a time there were three little sisters; and their names were 1 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; 2 3 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 4 and 5 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; 6 and they lived at the bottom of a well.1soup.p.contents [&apos;\n Once upon a time there were three little sisters; and their names were\n &apos;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt;, &apos;\n&apos;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &apos; \n and\n &apos;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;, &apos;\n and they lived at the bottom of a well.\n &apos;]12for i ,child in enumerate(soup.p.descendants): print(i,child) 0 Once upon a time there were three little sisters; and their names were 1 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; 2 3 &lt;span&gt;Elsie&lt;/span&gt; 4 Elsie 5 6 7 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; 8 Lacie 9 and 10 &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; 11 Tillie 12 and they lived at the bottom of a well.1soup.p.descendants &lt;generator object descendants at 0x107d06518&gt;父节点和祖先节点 1234567891011121314html = """&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse's story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt; &lt;p class="story"&gt;...&lt;/p&gt;""" 1from bs4 import BeautifulSoup 1soup = BeautifulSoup(html,'lxml') 1soup.a.parent &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;123456789html = """&lt;html&gt; &lt;body&gt; &lt;p class="story"&gt; &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;""" 1from bs4 import BeautifulSoup 1soup = BeautifulSoup(html,'lxml') 1type(soup.a.parents) generator1list(enumerate(soup.a.parents)) [(0, &lt;p class=&quot;story&quot;&gt; &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt;), (1, &lt;body&gt; &lt;p class=&quot;story&quot;&gt; &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;), (2, &lt;html&gt; &lt;body&gt; &lt;p class=&quot;story&quot;&gt; &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt;), (3, &lt;html&gt; &lt;body&gt; &lt;p class=&quot;story&quot;&gt; &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; &lt;/p&gt; &lt;/body&gt;&lt;/html&gt;)]兄弟节点 12345678910111213141516html = """&lt;html&gt; &lt;body&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt; &lt;span&gt;Elsie&lt;/span&gt; &lt;/a&gt; Hello &lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and &lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt; and they lived at the bottom of a well. &lt;/p&gt;""" 1soup = BeautifulSoup(html,'lxml') 1soup.a.next_sibling &apos;\n Hello\n &apos;1soup.a.previous_sibling &apos;\n Once upon a time there were three little sisters; and their names were\n &apos;1list(enumerate(soup.a.next_siblings)) [(0, &apos;\n Hello\n &apos;), (1, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;), (2, &apos; \n and\n &apos;), (3, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;), (4, &apos;\n and they lived at the bottom of a well.\n &apos;)]1list(enumerate(soup.a.previous_siblings)) [(0, &apos;\n Once upon a time there were three little sisters; and their names were\n &apos;)]next_sibling和previous_sibling分别获取节点的下一个和上一个兄弟元素，next_siblings和previous_siblings则分别返回所有前面和后面的兄弟节点的生成器 提取信息 123456789html = """&lt;html&gt; &lt;body&gt; &lt;p class="story"&gt; Once upon a time there were three little sisters; and their names were &lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;Bob&lt;/a&gt;&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; &lt;/p&gt;""" 1soup = BeautifulSoup(html,'lxml') 1type(soup.a.next_sibling) bs4.element.Tag1soup.a.next_sibling &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;1soup.a.next_sibling.string &apos;Lacie&apos;1type(soup.a.parents) generator1list(soup.a.parents)[0] &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Bob&lt;/a&gt;&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; &lt;/p&gt;1list(soup.a.parents)[0].attrs['class'] [&apos;story&apos;]如果返回结果是单个节点，那么可以直接调用string、attrs等属性获得其文本和属性；如果返回结果是多个节点的生成器，则可以转为列表后取出某个元素，然后再调用string、attrs等属性获取其对应节点的文本和属性。 ####方法选择器 find_all(name , attrs , recursive , text , **kwargs) name 12345678910111213141516171819202122html='''&lt;div class="panel"&gt; &lt;div class="panel-heading"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class="panel-body"&gt; &lt;ul class="list" id="list-1"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;li class="element"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class="list list-small" id="list-2"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.find_all(name='ul'))print(type(soup.find_all(name='ul')[0])) [&lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt;, &lt;ul class=&quot;list list-small&quot; id=&quot;list-2&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;/ul&gt;] &lt;class &apos;bs4.element.Tag&apos;&gt;12for ul in soup.find_all(name='ul'): print(ul.find_all(name='li')) [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;] [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]1234for ul in soup.find_all(name='ul'): print(ul.find_all(name='li')) for li in ul.find_all(name='li'): print(li.string) [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;] Foo Bar Jay [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;] Foo Barattrs 12345678910111213141516171819202122html='''&lt;div class="panel"&gt; &lt;div class="panel-heading"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class="panel-body"&gt; &lt;ul class="list" id="list-1" name="elements"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;li class="element"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class="list list-small" id="list-2"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.find_all(attrs=&#123;'id': 'list-1'&#125;))print(soup.find_all(attrs=&#123;'name': 'elements'&#125;)) [&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt;] [&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt;]1234from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.find_all(id='list-1'))print(soup.find_all(class_='element')) [&lt;ul class=&quot;list&quot; id=&quot;list-1&quot; name=&quot;elements&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt;] [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]text 123456789101112import rehtml='''&lt;div class="panel"&gt; &lt;div class="panel-body"&gt; &lt;a&gt;Hello, this is a link&lt;/a&gt; &lt;a&gt;Hello, this is a link, too&lt;/a&gt; &lt;/div&gt;&lt;/div&gt;'''from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.find_all(text=re.compile('link'))) [&apos;Hello, this is a link&apos;, &apos;Hello, this is a link, too&apos;]find() 1234567891011121314151617181920212223html='''&lt;div class="panel"&gt; &lt;div class="panel-heading"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class="panel-body"&gt; &lt;ul class="list" id="list-1"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;li class="element"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class="list list-small" id="list-2"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.find(name='ul'))print(type(soup.find(name='ul')))print(soup.find(class_='list')) &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;class &apos;bs4.element.Tag&apos;&gt; &lt;ul class=&quot;list&quot; id=&quot;list-1&quot;&gt; &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt; &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt; &lt;/ul&gt;1.find_parents()和find_parent()：前者返回所有祖先节点，后者返回直接父节点。2.find_next_siblings()和find_next_sibling()：前者返回后面所有的兄弟节点，后者返回后面第一个兄弟节点。3.find_previous_siblings()和find_previous_sibling()：前者返回前面所有的兄弟节点，后者返回前面第一个兄弟节点。4.find_all_next()和find_next()：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。5.find_all_previous()和find_previous()：前者返回节点后所有符合条件的节点，后者返回第一个符合条件的节点。 CSS选择器123456789101112131415161718192021222324html='''&lt;div class="panel"&gt; &lt;div class="panel-heading"&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt; &lt;div class="panel-body"&gt; &lt;ul class="list" id="list-1"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;li class="element"&gt;Jay&lt;/li&gt; &lt;/ul&gt; &lt;ul class="list list-small" id="list-2"&gt; &lt;li class="element"&gt;Foo&lt;/li&gt; &lt;li class="element"&gt;Bar&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;/div&gt;'''from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')print(soup.select('.panel .panel-heading'))print(soup.select('ul li'))print(soup.select('#list-2 .element'))print(type(soup.select('ul')[0])) [&lt;div class=&quot;panel-heading&quot;&gt; &lt;h4&gt;Hello&lt;/h4&gt; &lt;/div&gt;] [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;] [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;] &lt;class &apos;bs4.element.Tag&apos;&gt;嵌套选择 1234from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')for ul in soup.select('ul'): print(ul.select('li')) [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Jay&lt;/li&gt;] [&lt;li class=&quot;element&quot;&gt;Foo&lt;/li&gt;, &lt;li class=&quot;element&quot;&gt;Bar&lt;/li&gt;]获取属性 12345from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')for ul in soup.select('ul'): print(ul['id']) print(ul.attrs['id']) list-1 list-1 list-2 list-2获取文本 12345from bs4 import BeautifulSoupsoup = BeautifulSoup(html, 'lxml')for li in soup.select('li'): print('Get Text:', li.get_text()) print('String:', li.string) Get Text: Foo String: Foo Get Text: Bar String: Bar Get Text: Jay String: Jay Get Text: Foo String: Foo Get Text: Bar String: Bar原文：https://cuiqingcai.com/5548.html]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[re正则表达式]]></title>
    <url>%2F2018%2F09%2F09%2Fre%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[常见匹配模式 模式 描述 \w 匹配字母数字及下划线 \W 匹配非字母数字下划线 \s 匹配任意空白字符，等价于 [\t\n\r\f]. \S 匹配任意非空字符 \d 匹配任意数字，等价于 [0-9] \D 匹配任意非数字 \A 匹配字符串开始 \Z 匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串 \z 匹配字符串结束 \G 匹配最后匹配完成的位置 \n 匹配一个换行符 \t 匹配一个制表符 ^ 匹配字符串的开头 $ 匹配字符串的末尾。 . 匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。 […] 用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’ [^…] 不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。 * 匹配0个或多个的表达式。 + 匹配1个或多个的表达式。 ? 匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式 {n} 精确匹配n个前面表达式。 {n, m} 匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式 a&#124;b 匹配a或b ( ) 匹配括号内的表达式，也表示一个组 re.matchre.match 尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none。re.match(pattern, string, flags=0) 最常规的匹配12345678import recontent = 'Hello 123 4567 World_This is a Regex Demo'print(len(content))result = re.match('^Hello\s\d\d\d\s\d&#123;4&#125;\s\w&#123;10&#125;.*Demo$', content)print(result)print(result.group())print(result.span()) 41 &lt;_sre.SRE_Match object; span=(0, 41), match=&apos;Hello 123 4567 World_This is a Regex Demo&apos;&gt; Hello 123 4567 World_This is a Regex Demo (0, 41)泛匹配1234567import recontent = 'Hello 123 4567 World_This is a Regex Demo'result = re.match('^Hello.*Demo$', content)print(result)print(result.group())print(result.span()) &lt;_sre.SRE_Match object; span=(0, 41), match=&apos;Hello 123 4567 World_This is a Regex Demo&apos;&gt; Hello 123 4567 World_This is a Regex Demo (0, 41)匹配目标1234567import recontent = 'Hello 1234567 World_This is a Regex Demo'result = re.match('^Hello\s(\d+)\sWorld.*Demo$', content)print(result)print(result.group(1))print(result.span()) &lt;_sre.SRE_Match object; span=(0, 40), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt; 1234567 (0, 40)贪婪匹配123456import recontent = 'Hello 1234567 World_This is a Regex Demo'result = re.match('^He.*(\d+).*Demo$', content)print(result)print(result.group(1)) &lt;_sre.SRE_Match object; span=(0, 40), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt; 7非贪婪匹配123456import recontent = 'Hello 1234567 World_This is a Regex Demo'result = re.match('^He.*?(\d+).*Demo$', content)print(result)print(result.group(1)) &lt;_sre.SRE_Match object; span=(0, 40), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt; 1234567匹配模式1234567import recontent = '''Hello 1234567 World_Thisis a Regex Demo'''result = re.match('^He.*?(\d+).*?Demo$', content, re.S)print(result.group(1)) 1234567转义12345import recontent = 'price is $5.00'result = re.match('price is $5.00', content)print(result) None12345import recontent = 'price is $5.00'result = re.match('price is \$5\.00', content)print(result) &lt;_sre.SRE_Match object; span=(0, 14), match=&apos;price is $5.00&apos;&gt;总结：尽量使用泛匹配、使用括号得到匹配目标、尽量使用非贪婪模式、有换行符就用re.S re.searchre.search 扫描整个字符串并返回第一个成功的匹配。 12345import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'result = re.match('Hello.*?(\d+).*?Demo', content)print(result) None123456import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'result = re.search('Hello.*?(\d+).*?Demo', content)print(result)print(result.group(1)) &lt;_sre.SRE_Match object; span=(13, 53), match=&apos;Hello 1234567 World_This is a Regex Demo&apos;&gt; 1234567总结：为匹配方便，能用search就不用match 匹配演练12345678910111213141516171819202122232425import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;&lt;i class="fa fa-user"&gt;&lt;/i&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?active.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)if result: print(result.group(1), result.group(2)) 齐秦 往事随风12345678910111213141516171819202122232425import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)if result: print(result.group(1), result.group(2)) 任贤齐 沧海一声笑12345678910111213141516171819202122232425import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''result = re.search('&lt;li.*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html)if result: print(result.group(1), result.group(2)) beyond 光辉岁月re.findall搜索字符串，以列表形式返回全部能匹配的子串。 12345678910111213141516171819202122232425262728import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall('&lt;li.*?href="(.*?)".*?singer="(.*?)"&gt;(.*?)&lt;/a&gt;', html, re.S)print(results)print(type(results))for result in results: print(result) print(result[0], result[1], result[2]) [(&apos;/2.mp3&apos;, &apos;任贤齐&apos;, &apos;沧海一声笑&apos;), (&apos;/3.mp3&apos;, &apos;齐秦&apos;, &apos;往事随风&apos;), (&apos;/4.mp3&apos;, &apos;beyond&apos;, &apos;光辉岁月&apos;), (&apos;/5.mp3&apos;, &apos;陈慧琳&apos;, &apos;记事本&apos;), (&apos;/6.mp3&apos;, &apos;邓丽君&apos;, &apos;但愿人长久&apos;)] &lt;class &apos;list&apos;&gt; (&apos;/2.mp3&apos;, &apos;任贤齐&apos;, &apos;沧海一声笑&apos;) /2.mp3 任贤齐 沧海一声笑 (&apos;/3.mp3&apos;, &apos;齐秦&apos;, &apos;往事随风&apos;) /3.mp3 齐秦 往事随风 (&apos;/4.mp3&apos;, &apos;beyond&apos;, &apos;光辉岁月&apos;) /4.mp3 beyond 光辉岁月 (&apos;/5.mp3&apos;, &apos;陈慧琳&apos;, &apos;记事本&apos;) /5.mp3 陈慧琳 记事本 (&apos;/6.mp3&apos;, &apos;邓丽君&apos;, &apos;但愿人长久&apos;) /6.mp3 邓丽君 但愿人长久1234567891011121314151617181920212223242526import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''results = re.findall('&lt;li.*?&gt;\s*?(&lt;a.*?&gt;)?(\w+)(&lt;/a&gt;)?\s*?&lt;/li&gt;', html, re.S)print(results)for result in results: print(result[1]) [(&apos;&apos;, &apos;一路上有你&apos;, &apos;&apos;), (&apos;&lt;a href=&quot;/2.mp3&quot; singer=&quot;任贤齐&quot;&gt;&apos;, &apos;沧海一声笑&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/3.mp3&quot; singer=&quot;齐秦&quot;&gt;&apos;, &apos;往事随风&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/4.mp3&quot; singer=&quot;beyond&quot;&gt;&apos;, &apos;光辉岁月&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/5.mp3&quot; singer=&quot;陈慧琳&quot;&gt;&apos;, &apos;记事本&apos;, &apos;&lt;/a&gt;&apos;), (&apos;&lt;a href=&quot;/6.mp3&quot; singer=&quot;邓丽君&quot;&gt;&apos;, &apos;但愿人长久&apos;, &apos;&lt;/a&gt;&apos;)] 一路上有你 沧海一声笑 往事随风 光辉岁月 记事本 但愿人长久re.sub替换字符串中每一个匹配的子串后返回替换后的字符串。 12345import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'content = re.sub('\d+', '', content)print(content) Extra stings Hello World_This is a Regex Demo Extra stings12345import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'content = re.sub('\d+', 'Replacement', content)print(content) Extra stings Hello Replacement World_This is a Regex Demo Extra stings12345import recontent = 'Extra stings Hello 1234567 World_This is a Regex Demo Extra stings'content = re.sub('(\d+)', r'\1 8910', content)print(content) Extra stings Hello 1234567 8910 World_This is a Regex Demo Extra stings12345678910111213141516171819202122import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;''' 12345678910111213141516171819202122232425262728import rehtml = '''&lt;div id="songs-list"&gt; &lt;h2 class="title"&gt;经典老歌&lt;/h2&gt; &lt;p class="introduction"&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id="list" class="list-group"&gt; &lt;li data-view="2"&gt;一路上有你&lt;/li&gt; &lt;li data-view="7"&gt; &lt;a href="/2.mp3" singer="任贤齐"&gt;沧海一声笑&lt;/a&gt; &lt;/li&gt; &lt;li data-view="4" class="active"&gt; &lt;a href="/3.mp3" singer="齐秦"&gt;往事随风&lt;/a&gt; &lt;/li&gt; &lt;li data-view="6"&gt;&lt;a href="/4.mp3" singer="beyond"&gt;光辉岁月&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt;&lt;a href="/5.mp3" singer="陈慧琳"&gt;记事本&lt;/a&gt;&lt;/li&gt; &lt;li data-view="5"&gt; &lt;a href="/6.mp3" singer="邓丽君"&gt;但愿人长久&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/div&gt;'''html = re.sub('&lt;a.*?&gt;|&lt;/a&gt;', '', html)print(html)results = re.findall('&lt;li.*?&gt;(.*?)&lt;/li&gt;', html, re.S)print(results)for result in results: print(result.strip()) &lt;div id=&quot;songs-list&quot;&gt; &lt;h2 class=&quot;title&quot;&gt;经典老歌&lt;/h2&gt; &lt;p class=&quot;introduction&quot;&gt; 经典老歌列表 &lt;/p&gt; &lt;ul id=&quot;list&quot; class=&quot;list-group&quot;&gt; &lt;li data-view=&quot;2&quot;&gt;一路上有你&lt;/li&gt; &lt;li data-view=&quot;7&quot;&gt; 沧海一声笑 &lt;/li&gt; &lt;li data-view=&quot;4&quot; class=&quot;active&quot;&gt; 往事随风 &lt;/li&gt; &lt;li data-view=&quot;6&quot;&gt;光辉岁月&lt;/li&gt; &lt;li data-view=&quot;5&quot;&gt;记事本&lt;/li&gt; &lt;li data-view=&quot;5&quot;&gt; 但愿人长久 &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; [&apos;一路上有你&apos;, &apos;\n 沧海一声笑\n &apos;, &apos;\n 往事随风\n &apos;, &apos;光辉岁月&apos;, &apos;记事本&apos;, &apos;\n 但愿人长久\n &apos;] 一路上有你 沧海一声笑 往事随风 光辉岁月 记事本 但愿人长久re.compile将正则字符串编译成正则表达式对象 1将一个正则表达式串编译成正则对象，以便于复用该匹配模式 12345678import recontent = '''Hello 1234567 World_Thisis a Regex Demo'''pattern = re.compile('Hello.*Demo', re.S)result = re.match(pattern, content)#result = re.match('Hello.*Demo', content, re.S)print(result) &lt;_sre.SRE_Match object; span=(0, 40), match=&apos;Hello 1234567 World_This\nis a Regex Demo&apos;&gt;实战练习12345678910import requestsimport recontent = requests.get('https://book.douban.com/').textpattern = re.compile('&lt;li.*?cover.*?href="(.*?)".*?title="(.*?)".*?more-meta.*?author"&gt;(.*?)&lt;/span&gt;.*?year"&gt;(.*?)&lt;/span&gt;.*?&lt;/li&gt;', re.S)results = re.findall(pattern, content)for result in results: url, name, author, date = result author = re.sub('\s', '', author) date = re.sub('\s', '', date) print(url, name, author, date) https://book.douban.com/subject/26925834/?icn=index-editionrecommend 别走出这一步 [英]S.J.沃森 2017-1 https://book.douban.com/subject/26953532/?icn=index-editionrecommend 白先勇细说红楼梦 白先勇 2017-2-1 https://book.douban.com/subject/26959159/?icn=index-editionrecommend 岁月凶猛 冯仑 2017-2 https://book.douban.com/subject/26949210/?icn=index-editionrecommend 如果没有今天，明天会不会有昨天？ [瑞士]伊夫·博萨尔特（YvesBossart） 2017-1 https://book.douban.com/subject/27001447/?icn=index-editionrecommend 人类这100年 阿夏 2017-2 https://book.douban.com/subject/26864566/?icn=index-latestbook-subject 眼泪的化学 [澳]彼得·凯里 2017-2 https://book.douban.com/subject/26991064/?icn=index-latestbook-subject 青年斯大林 [英]西蒙·蒙蒂菲奥里 2017-3 https://book.douban.com/subject/26938056/?icn=index-latestbook-subject 带艾伯特回家 [美]霍默·希卡姆 2017-3 https://book.douban.com/subject/26954757/?icn=index-latestbook-subject 乳房 [美]弗洛伦斯·威廉姆斯 2017-2 https://book.douban.com/subject/26956479/?icn=index-latestbook-subject 草原动物园 马伯庸 2017-3 https://book.douban.com/subject/26956018/?icn=index-latestbook-subject 贩卖音乐 [美]大卫·伊斯曼 2017-3-1 https://book.douban.com/subject/26703649/?icn=index-latestbook-subject 被占的宅子 [阿根廷]胡利奥·科塔萨尔 2017-3 https://book.douban.com/subject/26578402/?icn=index-latestbook-subject 信仰与观看 [法]罗兰·雷希特(RolandRecht) 2017-2-17 https://book.douban.com/subject/26939171/?icn=index-latestbook-subject 妹妹的坟墓 [美]罗伯特·杜格尼(RobertDugoni) 2017-3-1 https://book.douban.com/subject/26972465/?icn=index-latestbook-subject 全栈市场人 Lydia 2017-2-1 https://book.douban.com/subject/26986928/?icn=index-latestbook-subject 终极X战警2 [英]马克·米勒&amp;nbsp;/&amp;nbsp;[美]亚当·库伯特 2017-3-15 https://book.douban.com/subject/26948144/?icn=index-latestbook-subject 格调（修订第3版） [美]保罗·福塞尔（PaulFussell） 2017-2 https://book.douban.com/subject/26945792/?icn=index-latestbook-subject 原谅石 [美]洛里·斯皮尔曼 2017-2 https://book.douban.com/subject/26974207/?icn=index-latestbook-subject 庇护二世闻见录 [意]皮科洛米尼 2017-2 https://book.douban.com/subject/26983143/?icn=index-latestbook-subject 遇见野兔的那一年 [芬]阿托·帕西林纳 2017-3-1 https://book.douban.com/subject/26976429/?icn=index-latestbook-subject 鲍勃·迪伦：诗人之歌 [法]让-多米尼克·布里埃 2017-4 https://book.douban.com/subject/26962860/?icn=index-latestbook-subject 牙医谋杀案 [英]阿加莎·克里斯蒂 2017-3 https://book.douban.com/subject/26923022/?icn=index-latestbook-subject 石挥谈艺录：把生命交给舞台 石挥 2017-2 https://book.douban.com/subject/26897190/?icn=index-latestbook-subject 理想 [美]安·兰德 2017-2 https://book.douban.com/subject/26985981/?icn=index-latestbook-subject 青苔不会消失 袁凌 2017-4 https://book.douban.com/subject/26984949/?icn=index-latestbook-subject 地下铁道 [美]科尔森·怀特黑德（ColsonWhitehead） 2017-3 https://book.douban.com/subject/26944012/?icn=index-latestbook-subject 极简进步史 [英]罗纳德·赖特 2017-4-1 https://book.douban.com/subject/26969002/?icn=index-latestbook-subject 驻马店伤心故事集 郑在欢 2017-2 https://book.douban.com/subject/26854223/?icn=index-latestbook-subject 致薇拉 [美]弗拉基米尔·纳博科夫 2017-3 https://book.douban.com/subject/26841616/?icn=index-latestbook-subject 北方档案 [法]玛格丽特·尤瑟纳尔 2017-2 https://book.douban.com/subject/26980391/?icn=index-latestbook-subject 食帖15：便当灵感集 林江 2017-2 https://book.douban.com/subject/26958882/?icn=index-latestbook-subject 生火 [法]克里斯多夫·夏布特（ChristopheChabouté）编绘 2017-3 https://book.douban.com/subject/26989163/?icn=index-latestbook-subject 文明之光（第四册） 吴军 2017-3-1 https://book.douban.com/subject/26878906/?icn=index-latestbook-subject 公牛山 [美]布赖恩·帕诺威奇 2017-2 https://book.douban.com/subject/26989534/?icn=index-latestbook-subject 几乎消失的偷闲艺术 [加拿大]达尼·拉费里埃 2017-4 https://book.douban.com/subject/26939973/?icn=index-latestbook-subject 散步去 [日]谷口治郎 2017-3 https://book.douban.com/subject/26865333/?icn=index-latestbook-subject 中国1945 [美]理查德·伯恩斯坦(RichardBernstein) 2017-3-1 https://book.douban.com/subject/26989242/?icn=index-latestbook-subject 有匪2：离恨楼 Priest 2017-3 https://book.douban.com/subject/26985790/?icn=index-latestbook-subject 女人、火与危险事物 [美]乔治·莱考夫 2017-3 https://book.douban.com/subject/26972277/?icn=index-latestbook-subject 寻找时间的人 [爱尔兰]凯特·汤普森 2017-3 https://www.douban.com/note/610758170/ 白先勇细说红楼梦【全二册】 白先勇 2017-2-1 https://read.douban.com/ebook/31540864/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 奇爱博士 [英]彼得·乔治 2016-8-1 https://read.douban.com/ebook/31433872/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 在时光中盛开的女子 李筱懿 2017-3 https://read.douban.com/ebook/31178635/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 如何高效记忆（原书第2版） [美]肯尼思•希格比（KennethL.Higbee） 2017-3-5 https://read.douban.com/ebook/31358183/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 愿无岁月可回头 回忆专用小马甲 2016-9 https://read.douban.com/ebook/31341636/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 走神的艺术与科学 [新西兰]迈克尔·C.科尔巴里斯 2017-3-1 https://read.douban.com/ebook/27621094/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 神秘的量子生命 [英]吉姆•艾尔－哈利利/约翰乔•麦克法登 2016-8 https://read.douban.com/ebook/31221966/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 寻找时间的人 [爱尔兰]凯特·汤普森 2017-3 https://read.douban.com/ebook/31481323/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 山之四季 [日]高村光太郎 2017-1 https://read.douban.com/ebook/31154855/?dcs=book-hot&amp;amp;dcm=douban&amp;amp;dct=read-subject 东北游记 [美]迈克尔·麦尔 2017-1]]></content>
      <categories>
        <category>re正则</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python高效实用方法]]></title>
    <url>%2F2018%2F09%2F08%2Fpython%E9%AB%98%E6%95%88%E5%AE%9E%E7%94%A8%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.斐波那契数列(生兔子问题) 123456789101112131415161718192021222324252627282930313233343536373839404142In [1]: def fib(n): ...: a = 1 ...: b = 1 ...: for i in range(n): ...: yield a ...: a,b = b,a+b ...: In [2]: num = fib(5)#报错In [3]: num.next()---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-3-4f80ce795333&gt; in &lt;module&gt;()----&gt; 1 num.next()AttributeError: 'generator' object has no attribute 'next'#使用__next__()In [6]: num.__next__()Out[6]: 1In [7]: num.__next__()Out[7]: 1In [8]: num.__next__()Out[8]: 2In [9]: num.__next__()Out[9]: 3In [10]: num.__next__()Out[10]: 5In [11]: num.__next__()---------------------------------------------------------------------------StopIteration Traceback (most recent call last)&lt;ipython-input-11-4ec40755f0d5&gt; in &lt;module&gt;()----&gt; 1 num.__next__()StopIteration: 2.三元运算符 lambda表达式 12345678#为真时的结果 if 判定条件 else 为假时的结果 In [19]: 4 if 4&gt;5 else 5Out[19]: 5#lambda表达式In [12]: (lambda x:x+x)(5)Out[12]: 10In [13]: (lambda x,y:x+y)(2,5)Out[13]: 7 3.filter过滤器函数 (python2中直接返回一个List/String/Tuple,python3中返回迭代器对象,可用list(filter())转换) 123456789101112131415161718192021In [26]: def f(x):return x%2!=0 and x%3!=0In [27]: filter(f,range(2,25))Out[27]: &lt;filter at 0x7ffa90451390&gt;In [28]: g = filter(f,range(2,25))In [29]: g.__next__()Out[29]: 5In [30]: g.__next__()Out[30]: 7In [31]: g.__next__()Out[31]: 11In [32]: g.__next__()Out[32]: 13In [33]: list(g)Out[33]: [17, 19, 23] 4.map函数(为列表推导式[f(x) for x in iterable]) 12345678910111213141516171819202122232425In [43]: def f(x,y): ...: return (x,y) In [37]: x = [1,3,5,7,9]In [38]: y = ['a','b','c','d','e']In [44]: map(f,x,y)Out[44]: &lt;map at 0x7ffa9045c5f8&gt;In [45]: g = map(f,x,y)In [46]: g.__next__()Out[46]: (1, 'a')In [47]: g.__next__()Out[47]: (3, 'b')In [48]: list(g)Out[48]: [(5, 'c'), (7, 'd'), (9, 'e')]In [50]: g = map(f,x,y)In [51]: dict(g)Out[51]: &#123;1: 'a', 3: 'b', 5: 'c', 7: 'd', 9: 'e'&#125; 5.reduce函数 123456789In [52]: from functools import reduceIn [53]: l = [0,1,2,3,4,5,6]In [54]: def f(x,y): ...: return (x+y) In [55]: reduce(f,l)Out[55]: 21 6.zip函数[转化字典可dict(zip())] 12345678910111213141516171819202122232425262728In [56]: x = [1,2,3]In [57]: y = [4,5,6]In [58]: z = [7,8,9]In [59]: xyz = zip(x,y,z)In [60]: xyzOut[60]: &lt;zip at 0x7ffa90460788&gt;In [61]: list(xyz)Out[61]: [(1, 4, 7), (2, 5, 8), (3, 6, 9)]#zip和*zipIn [13]: x = [1,2,3]In [14]: y = ["a","b","c"]In [15]: z = ["一","二","三"]In [16]: zipa = list(zip(x,y,z))In [17]: list(zipa)Out[17]: [(1, 'a', '一'), (2, 'b', '二'), (3, 'c', '三')]In [18]: list(zip(*zipa))Out[18]: [(1, 2, 3), ('a', 'b', 'c'), ('一', '二', '三')] 7.列表推导式 12345678In [36]: l = [1,2,3,4,5,6,7,8,9]In [37]: [x*2 for x in l if x&gt;2]Out[37]: [6, 8, 10, 12, 14, 16, 18]In [39]: dict([(x,x*2) for x in l])Out[39]: &#123;1: 2, 2: 4, 3: 6, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18&#125; 8.字典推导式 1234In [48]: d = &#123;x:x*2 for x in range(1,5)&#125;In [49]: dOut[49]: &#123;1: 2, 2: 4, 3: 6, 4: 8&#125; 9.集合推导式(去重) 123456In [50]: l = [1,2,4,5,7,3,2,4,6,2,4,6]In [51]: s = &#123;x for x in l&#125;In [52]: sOut[52]: &#123;1, 2, 3, 4, 5, 6, 7&#125; 10.计数器功能(和词频统计差不多) 123456789101112In [53]: from collections import CounterIn [54]: c = Counter("Hello world")In [55]: cOut[55]: Counter(&#123;'H': 1, 'e': 1, 'l': 3, 'o': 2, ' ': 1, 'w': 1, 'r': 1, 'd': 1&#125;)#找出出现次数最多的前一个In [56]: c.most_common(1)Out[56]: [('l', 3)]#找出出现次数最多的前两个In [57]: c.most_common(2)Out[57]: [('l', 3), ('o', 2)] 11.sort和sorted 123456789101112131415161718192021222324252627282930313233343536373839#sortIn [4]: x = [2,1,4,6,7,3,2,1]In [5]: x.sort()In [6]: xOut[6]: [1, 1, 2, 2, 3, 4, 6, 7]#sortedIn [7]: sorted("Hello world")Out[7]: [' ', 'H', 'd', 'e', 'l', 'l', 'l', 'o', 'o', 'r', 'w']#按照l第三个数进行排序(默认由小到大)In [8]: l = [(1,4,2),(2,4,3),(4,2,5)]In [12]: sorted(l,key=lambda l:l[2])Out[12]: [(1, 4, 2), (2, 4, 3), (4, 2, 5)]#reverse=False默认为由小到大升序#reverse=True默认为由大到小降序In [13]: sorted(l,key=lambda l:l[2],reverse=True)Out[13]: [(4, 2, 5), (2, 4, 3), (1, 4, 2)]#python3中使用cmp会报错,建议使用keyIn [14]: sorted(l, cmp=lambda x : cmp(x[2]))---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-14-a2e338d8ccdd&gt; in &lt;module&gt;()----&gt; 1 sorted(l, cmp=lambda x : cmp(x[2]))TypeError: 'cmp' is an invalid keyword argument for this function#可使用itemgetter进行多级排序In [15]: from operator import itemgetter, attrgetter #按照第三个数进行排序In [16]: sorted(l, key=itemgetter(2))Out[16]: [(1, 4, 2), (2, 4, 3), (4, 2, 5)]#先按照第二个数进行排序,再按照第一个数进行排序In [19]: sorted(l, key=itemgetter(1,0))Out[19]: [(4, 2, 5), (1, 4, 2), (2, 4, 3)]#对字典排序,排序后转化为listIn [20]: d = &#123;"a":1,"b":3,"c":2&#125;In [22]: sorted(d.items(),key = itemgetter(1),reverse=True)Out[22]: [('b', 3), ('c', 2), ('a', 1)]#元组不可转为字典 12.切片[起始位置:结束位置:步长值(默认1)] 1234567891011121314151617181920212223242526272829303132#切片的结果起始位置为下标,结束位置为下标的前一位In [23]: l = [0,1,2,3,4,5]In [24]: l[1:5]Out[24]: [1, 2, 3, 4]#当切片超出范围时不报错,取到最后一位In [25]: l[1:7]Out[25]: [1, 2, 3, 4, 5]#设置步长为2In [26]: l[1:5:2]Out[26]: [1, 3]#倒叙In [27]: l[::-1]Out[27]: [5, 4, 3, 2, 1, 0]#取偶数In [32]: l[::2]Out[32]: [0, 2, 4]#取奇数In [33]: l[1::2]Out[33]: [1, 3, 5]#取倒叙In [29]: l[-2:-5:-1]Out[29]: [4, 3, 2]In [31]: l[-5:-2]Out[31]: [1, 2, 3]]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python对数据的分解操作]]></title>
    <url>%2F2018%2F09%2F06%2Fpython%E5%AF%B9%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%86%E8%A7%A3%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[1.list 123456789101112In [6]: my_list = ['a','b','c']In [7]: a,b,c = my_listIn [8]: aOut[8]: 'a'In [9]: bOut[9]: 'b'In [10]: cOut[10]: 'c' 2.tuple 123456789101112In [11]: my_tuple = ('a','b','c')In [12]: a,b,c = my_tupleIn [13]: aOut[13]: 'a'In [14]: bOut[14]: 'b'In [15]: cOut[15]: 'c' 如果个数不匹配会报错 1234567In [16]: a,b = my_tuple---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-16-7f79ac6a61ca&gt; in &lt;module&gt;()----&gt; 1 a,b = my_tupleValueError: too many values to unpack (expected 2) 解决办法 1234567In [18]: a,*b = my_tupleIn [19]: aOut[19]: 'a'In [20]: bOut[20]: ['b', 'c'] 123456789101112131415In [21]: line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'In [22]: uname,*fields,homedir,sh = line.split(':')In [23]: unameOut[23]: 'nobody'In [24]: homedirOut[24]: '/var/empty'In [25]: shOut[25]: '/usr/bin/false'In [26]: fieldsOut[26]: ['*', '-2', '-2', 'Unprivileged User'] 限长队列操作(collections库) 12345678910111213141516171819202122In [3]: from collections import dequeIn [4]: q= deque(maxlen=3)In [5]: q.append(a)---------------------------------------NameErrorTraceback (most recent call last)&lt;ipython-input-5-1f9d58a866d2&gt; in &lt;module&gt;()----&gt; 1 q.append(a)NameError: name 'a' is not definedIn [6]: q.append(1)In [7]: q.append(2)In [8]: q.append(3)In [9]: q.append(4)In [10]: qOut[10]: deque([2, 3, 4]) 无限长队列操作(默认右,指定appendleft,popleft) 1234567891011121314151617181920212223242526In [19]: q = deque()In [20]: q.append(1)In [21]: q.append(2)In [22]: q.append(3)In [23]: q.append(4)In [24]: qOut[24]: deque([1, 2, 3, 4])In [25]: q.appendleft(5)In [26]: qOut[26]: deque([5, 1, 2, 3, 4])In [27]: q.pop()Out[27]: 4In [28]: qOut[28]: deque([5, 1, 2, 3])In [29]: q.popleft()Out[29]: 5 找到最大或最小的N个元素 123456789In [30]: import heapqIn [31]: nums = [1,4,6,8,29,-3,9,-27,-32]In [32]: heapq.nlargest(3,nums)Out[32]: [29, 9, 8]In [33]: heapq.nsmallest(3,nums)Out[33]: [-32, -27, -3]]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[json编码]]></title>
    <url>%2F2018%2F09%2F04%2Fjson%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[json.dumps() 将字典转化为字符串 1234567891011In [1]: import jsonIn [2]: d = &#123;"name":"daming"&#125;In [3]: json_dumps_d = json.dumps(d)In [4]: print(d,json_dumps_d)&#123;'name': 'daming'&#125; &#123;"name": "daming"&#125;In [5]: print(type(d),type(json_dumps_d))&lt;class 'dict'&gt; &lt;class 'str'&gt; json.loads()将字符串转化为字典 123456789In [6]: s = '&#123;"name":"lingling"&#125;'In [7]: json_loads_s = json.loads(s)In [8]: print(s,json_loads_s)&#123;"name":"lingling"&#125; &#123;'name': 'lingling'&#125;In [9]: print(type(s),type(json_loads_s))&lt;class 'str'&gt; &lt;class 'dict'&gt; json.dump()将json写入文件 12345In [10]: s_json = "&#123;'age':18&#125;"In [11]: f = open(文件名.json,'w',encoding='utf-8')In [12]: json.dump(s_json,f) json.load()读取json文件 12345In [11]: f = open(文件名.json,'r',encoding='utf-8')In [13]: data = json.load(f)In [14]: print(data) decode解码encode编码 12------decode ----------- encodebytes ------&gt; str(unicode)------&gt;bytes]]></content>
      <categories>
        <category>json</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[单例模式和装饰器]]></title>
    <url>%2F2018%2F09%2F03%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[new方法实现单例模式 12345class Singleton(object): def __new__(cls,*args,**kwargs): if not hasattr(cls,'_instance'): cls._instance = super(Singleton,cls).__new__(cls,*args,**kwargs) return cls._instance 装饰器 1234567891011121314151617181920from time import timeimport datetimedef wrap(func): def timer(*args,**kwargs): t1 = time() temp_time = datetime.datetime.now() func() t2 = time() result = t2-t1 start_time = temp_time.strftime('%c') print('the start time is %s' % start_time) print("the running time is %f seconds" % result) return timer@wrapdef functions(): for i in range(1000): print (i)functions()]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis发送订阅]]></title>
    <url>%2F2018%2F09%2F02%2Fredis%E5%8F%91%E9%80%81%E8%AE%A2%E9%98%85%2F</url>
    <content type="text"><![CDATA[订阅者 123456shanghaimei@shanghaimei:~$ redis-cli127.0.0.1:6379&gt; SUBSCRIBE wechatReading messages... (press Ctrl-C to quit)1) "subscribe"2) "wechat"3) (integer) 1 发送者 1234127.0.0.1:6379&gt; PUBLISH wechat "hello!"(integer) 1127.0.0.1:6379&gt; PUBLISH wechat "Nice to meet you!"(integer) 1 订阅者 1234561) "message"2) "wechat"3) "hello!"1) "message"2) "wechat"3) "Nice to meet you!" python实现 (help类) 123456789101112131415161718192021import redisclass RedisHelper: def __init__(self): self.__conn = redis.Redis(host='********') self.chan_sub = 'test' self.chan_pub= 'test'#发送消息 def public(self,msg): self.__conn.publish(self.chan_pub,msg) return True#订阅 def subscribe(self): #打开收音机 pub = self.__conn.pubsub() #调频道 pub.subscribe(self.chan_sub) #准备接收 pub.parse_response() return pub 订阅者 1234567from redishelper import RedisHelperobj = RedisHelper()redis_sub = obj.subscribe()while True: msg = redis_sub.parse_response() print('接收：',msg) 发布者 123from redishelper import RedisHelperobj = RedisHelper()obj.public('*********') #发送的内容 原文地址:https://www.cnblogs.com/gaizhongfeng/p/8109982.html]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django接收前端返回的json格式数据]]></title>
    <url>%2F2018%2F08%2F29%2FDjango%E6%8E%A5%E6%94%B6%E5%89%8D%E7%AB%AF%E8%BF%94%E5%9B%9E%E7%9A%84json%E6%A0%BC%E5%BC%8F%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[post接收字符串 1234567891011121314151617def subscription(request): msg = request.POST.get('msg') # tel_no = request.POST.get('tel_no') # email = request.POST.get('email') # ico_id = request.POST.get('ico_id') data = base64.b64decode(msg) data = data.decode('utf-8') data = json.loads(data) client = pymongo.MongoClient(host = 'localhost',port = 27017) db = client.users my_set = db.user if 'ico_id' not in data.keys(): return HttpResponse(json.dumps(&#123;"result_code":1&#125;)) result_code = my_set.insert(&#123;"tel_no":data.get('tel_no'),"email":data.get('email'),"ico_id":data.get('ico_id'),'date':datetime.datetime.now()&#125;) return HttpResponse(json.dumps(&#123;"result_code":0&#125;)) post接收json格式 123456789101112131415161718192021222324252627def selectedico(request): if request.method == 'POST': web_id = json.loads(request.body.decode().replace("'", "\"")).get('id') client = pymongo.MongoClient(host = 'localhost',port = 27017) db = client.webdata my_set = db.webchinadata values = [] #print(web_id) print(request.body.decode()) for val in my_set.find(): # value = value.decode('utf-8') # val = json.loads(value) val["_id"] = str(val["_id"]) val["date"] = str(val["date"]) discount = (''.join(val["discounts"])).split('\n') dis = [x.strip(' ') for x in discount if x != ''] val["discounts"] = dis val["accept_coins"] = val["accept_coins"].split(",") details = (''.join(val["details"])).replace('\n','') val["details"] = details #print(val["_id"]) if val["_id"] == web_id: values.append(val) return HttpResponse(json.dumps(values,ensure_ascii=False),content_type="application/json;charset=utf-8")]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql命令]]></title>
    <url>%2F2018%2F08%2F26%2Fmysql%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[检索数据 检索单个列: 1SELECT column FROM tablename; 检索多个列: 1SELECT column1,column2, FROM tablename; 检索所有列: 1SELECT * FROM tablename; 检索不同行: 1SELECT DISTINCE column FROM tablename; 限制结果: 1SELETC column FROM tablename LIMIT 1; 完全限定: 1SELECT table.column FROM tablename; 排序检索数据 排序数据: 1SELECT column FROM tablename ORDER BY column; 多列排序: 1SELECT column1,column2 FROM tablename ORDER BY column1,column2; 指定序列排序: 升序: 1SELECT column1,column2 FROM tablename ORDER BY column1; 降序: 1SELECT column1,column2 FROM tablename ORDER BY column1 DESC; ​ 过滤数据 where语句: 1SELECT column1,column2 FROM tablename WHERE column = a; where子句: 检查单个值: 1SELECT column1, column2 FROM tablename WHERE column1 = 'a'; 不匹配检查: 1SELECT column1, column2 FROM tablename WHERE column1 &lt;&gt; 100; 范围值检查: 1SELECT column1,column2 FROM tablename WHERE column1 BETWEEN 1 AND 2; 空只检查: 1SELECT column1 FROM tablename WHERE column2 IS NULL; ​ 数据过滤 组合where子句： AND操作符: 1SELECT column1, column2, column3 FROM tablename WHERE column1 = 1 AND column2 &lt;= 2; OR操作符: 1SELECT column1,column2 FROM tablename WHERE column1 = 1 OR column2 = 2; 计算次序(优先处理AND操作符) IN操作符: 1SELECT column1,column2 FROM tablename WHERE column3 IN (1,2); NOT操作符: 1SELECT column1,column2 FROM tablename WHERE column3 NOT IN (1,2); ​ 通配符过滤 LIKE操作符: 百分号通配符: 12# 搜索任何位置包含文本jet的值SELECT column1, column2 FROM tablename WHERE column2 LIKE "%jet%"; 下划线通配符 12# 下划线通配符只匹配单个字符SELECT column1,column2 FROM tablename WHERE column2 LIKE '_ton anvil'; ​ 正则表达式搜索 基本字符匹配 12SELECT column1 FROM tablename WHERE column1 REGEXP '1000' ORDER BY column1;# REGEXP 后跟的东西作为正则表达式处理 OR匹配 1SELECT column1 FROM tablenam WHERE column1 REGEXP '1000|2000' ORDER BY column1; 匹配几个字符之一 12SELECT column1 FROM tablename WHERE column1 REGEXP '[123]' ORDER BY column1;# 匹配1或2或3 ​ 计算字段 拼接字段(concatenate) 12SELECT Concat(column1,"(", column2,")") FROM tablename ORDER BY column1;# 将column1和column2拼接在一起并返回 Trim()函数 123SELECT Concat(RTrim(column1),'(',RTrim(column2),')') FROM tablename ORDER BY column1;# RTrim去掉右侧空格 LTrim去掉左侧空格 Trim去掉两侧空格 使用别名 12SELECT Concat(RTrim(column1),'(',RTrim(column2),')') AS column3 FROM tablename ORDER BY column1;# 将column1和column2合并且返回一个名为column3的列 算术计算 12345SELECT column1,column2,column3 FROM tablename WHERE column4 = 100;# 返回所有满足column4为100的值SELECT column1,column2*column3 AS column6 FROM tablename WHERE column4 = 100;# 返回所有满足column4为100的值,其中column6是column2和column3的乘积 使用数据处理函数 使用函数: 文本处理函数： 函数 说明 Left() 返回串左边的字符 Length() 返回串的长度 Locate() 找出串的一个字串 Lower() 将串转换成小写 LTrim() 去掉串左边的空格 Right() 返回串右边的字符 RTrim() 去掉串右边的空格 Soundex() 返回串的SOUNDEX值 SubString() 返回子串的字符 Upper() 将串转换成大写 日期和时间处理函数: 函数 说明 AddDate() 增加一个日期（天，周） AddTime() 增加一个时间（时，分） CurDate() 返回当前日期 CurTime() 返回当前时间 Date() 返回日期时间的日期部分 DateDiff() 计算两个日期之差 Date_Add() 高度灵活的日期运算函数 Date_Format() 返回一个格式化的日期或时间串 Day() 返回一个日期的天数部分 DayofWeek() 对于一个日期， 返回对应的星期几 Hour() 返回一个时间的小时部分 Minute() 返回一个时间的分钟部分 Month() 返回一个日期的月份部分 Now() 返回当前日期和时间 Second() 返回一个时间的秒部分 Time() 返回一个时间的时间部分 Year() 返回一个日期的年份部分 数值处理函数 函数 说明 Abs() 返回一个数的绝对值 Cos() 返回一个角度的余弦 Exp() 返回一个数的指数值 Mod() 返回除操作的余数 Pi() 返回圆周率 Rand() 返回一个随机数 Sin() 返回一个角度的余弦 Sqrt() 返回一个数的平方根 Tan() 返回一个角度的正切]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy数组]]></title>
    <url>%2F2018%2F08%2F18%2FNumpy%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[内容参考:Numpy库常用函数大全 数组的属性12345678910np.ndim ：维度np.shape ：各维度的尺度np.size ：元素的个数np.dtype ：元素的类型np.itemsize ：每个元素的大小，以字节为单位 ，每个元素占4个字节 栗子: 1234567891011121314import numpy as npn = np.array([2,5,7,3])narray([2, 5, 7, 3])n.ndim1n.shape(4,)n.size4n.dtypedtype('int64')n.itemsize8 数组的创建1234567891011121314151617181920212223242526np.arange(n) :元素从0到n-1的ndarray类型np.empty(shape) :生成空数组np.ones(shape): 生成全为1的矩阵np.zeros((shape)， ddtype = np.int32) ： 生成int32型的全为0的矩阵np.full(shape, 5): 生成全为5的矩阵np.eye(n) : 生成单位矩阵np.ones_like(a) : 按数组a的形状生成全1的数组np.zeros_like(a): 同理np.full_like (a, val) : 同理np.linspace（1,10,4）： 根据起止数据等间距地生成数组np.linspace（1,10,4, endpoint = False）：endpoint 表示10是否作为生成的元素np.logspace(0,2,10,base=10/2) :生成0到2之间10个以10/2为底的等比数列np.concatenate((arr1,arr2),axis=0/1):数组的拼接,两个数组的形状要一样 扩展小知识:单位矩阵 123在矩阵乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1，这种矩阵被称为单位矩阵。它是个方阵，从左上角到右下角的对角线（称为主对角线)上的元素均为1。除此以外全都为0。根据单位矩阵的特点，任何矩阵与单位矩阵相乘都等于本身，而且单位矩阵因此独特性在高等数学中也有广泛应用 栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#指定数组的类型a = np.array([[1,2], [3,4]], dtype=complex)aarray([[1.+0.j, 2.+0.j], [3.+0.j, 4.+0.j]])#np.zeros((shape),dtype = np.int64) 生成int64型的全0矩阵b = np.zeros((3,4),dtype = np.int64)barray([[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]])b.dtypedtype('int64')#np.ones((2,3),dtype = np.int32) 生成int32型的全1矩阵c = np.ones((2,3),dtype = np.int32)carray([[1, 1, 1], [1, 1, 1]], dtype=int32)#np.empty(shape) 生成空数组d = np.empty((3,4)) darray([[1.69743644e-316, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000], [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000], [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000]])#np.arange(n) 元素从0到n-1的ndarray类型e = np.arange(5)earray([0, 1, 2, 3, 4])e.dtypedtype('int64')#np.full(shape, n): 生成全为n的矩阵f = np.full((3,5),5)farray([[5, 5, 5, 5, 5], [5, 5, 5, 5, 5], [5, 5, 5, 5, 5]])#生成单位矩阵g = np.eye(4)garray([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]])#np.linspace（1,10,4）： 根据起止数据等间距地生成数组,包括10在内h = np.linspace(1,10,4) #(10-1)/(4-1) = 3harray([ 1., 4., 7., 10.])#np.linspace（1,10,4）： 根据起止数据等间距地生成数组,endpoint 表示10是否作为生成的元素,不包括10i = np.linspace(1,10,4,endpoint=False) #(10-1)/4=2.25iarray([1. , 3.25, 5.5 , 7.75])#默认以10为底的等比数列np.logspace(0,9,10)array([1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08, 1.e+09])#把底数变为2np.logspace(0,9,10,base=2)array([ 1., 2., 4., 8., 16., 32., 64., 128., 256., 512.])#np.concatenate() 数组的拼接arr2 = np.array([[7,5],[6,1]])arr3 = np.array([[2,3,4],[5,6,7]])con3 = np.concatenate((arr2,arr3),axis =1 ) #1行相同,列不同,追加列con3array([[7, 5, 2, 3, 4], [6, 1, 5, 6, 7]])arr4 = np.array([[2,5],[3,6],[8,5]])con4 = np.concatenate((arr2,arr4),axis = 0) #0列相同,行不同,追加行con4array([[7, 5], [6, 1], [2, 5], [3, 6], [8, 5]]) 数组的随机函数12345678910111213141516171819rand(nd0,nd1... )创建随机数数组，浮点数，[0, 1），均匀分布randn(nd0,nd1... )创建随机函数数组，标准正态分布randint(low, high, shape )根据shape创建随机整数或整数数组，范围是[low, high)seed(n) 随机数种子,seed值的有效次数仅为一次,若要保证每次产生的随机数相同，则需要在调用随机数函数之前再次使用相同的seed值shuffle(a) : 根据数组a的第一轴进行随机排列，改变数组a permutation(a) : 根据数组a的第一轴进行随机排列， 但是不改变原数组，将生成新数组 choice(a[, size, replace, p]) : 从一维数组a中以概率p抽取元素， 形成size形状新数组，replace表示是否可以重用元素，默认为Falseuniform(low, high, size) : 产生均匀分布的数组，起始值为low，high为结束值，size为形状 normal(loc, scale, size) : 产生正态分布的数组， loc为均值，scale为标准差，size为形状 poisson(lam, size) : 产生泊松分布的数组， lam随机事件发生概率，size为形状 栗子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#rand(nd0,nd1... )创建随机数数组，浮点数，[0, 1），均匀分布，生成各个纬度的数量a = np.random.rand(1,2,3,4)aarray([[[[9.18018356e-04, 4.87832688e-01, 8.76879929e-01, 7.67476807e-01], [2.17625454e-01, 7.78172886e-01, 7.14865908e-02, 5.32607565e-01], [1.35164249e-01, 9.54127941e-01, 8.70819401e-01, 1.79284373e-01]], [[3.19823462e-01, 8.67019344e-01, 1.73814796e-01, 3.98941917e-01], [1.19521004e-01, 9.41800920e-01, 9.31448299e-01, 5.85017892e-01], [4.39802293e-01, 6.76682232e-01, 3.31631470e-01, 7.45757805e-01]]]])#randn(nd0,nd1... )创建随机函数数组，标准正态分布b = np.random.randn(1,2,3,4)barray([[[[ 2.17407732, -0.14816932, -0.05172504, 1.34213426], [-0.32645533, -0.88477566, 1.77405832, -0.10384156], [-1.73150275, 0.92107874, -1.40861082, -2.65470768]], [[ 0.70930984, 1.2631603 , 0.85013548, 0.83539502], [-0.47923866, -0.09688473, -0.76229436, -0.94953195], [ 1.06997304, -1.80410918, -0.54808506, 1.74663608]]]])#randint(low, high, shape )根据shape创建随机整数或整数数组，范围是[low, high)c = np.random.randint(2,10,(4,6))carray([[6, 4, 7, 4, 7, 6], [8, 7, 8, 4, 8, 4], [5, 7, 4, 6, 9, 5], [5, 8, 5, 3, 4, 7]])#seed(n) 随机数种子,seed值的有效次数仅为一次,若要保证每次产生的随机数相同，则需要在调用随机数函数之前再次使用相同的seed值np.random.seed(4)d = np.random.randn(5,5)darray([[ 0.05056171, 0.49995133, -0.99590893, 0.69359851, -0.41830152], [-1.58457724, -0.64770677, 0.59857517, 0.33225003, -1.14747663], [ 0.61866969, -0.08798693, 0.4250724 , 0.33225315, -1.15681626], [ 0.35099715, -0.60688728, 1.54697933, 0.72334161, 0.04613557], [-0.98299165, 0.05443274, 0.15989294, -1.20894816, 2.22336022]])e = np.random.randn(5,5) #np.random.normal(loc=0, scale=1, size) earray([[ 0.39429521, 1.69235772, -1.11281215, 1.63574754, -1.36096559], [-0.65122583, 0.54245131, 0.04800625, -2.35807363, -1.10558404], [ 0.83783635, 2.08787087, 0.91484096, -0.27620335, 0.7965119 ], [-1.14379857, 0.50991978, -1.3474603 , -0.0093601 , -0.13070464], [ 0.80208661, -0.30296397, 1.20200259, -0.19674528, 0.8365287 ]])np.random.seed(4)f = np.random.randn(5,5)farray([[ 0.05056171, 0.49995133, -0.99590893, 0.69359851, -0.41830152], [-1.58457724, -0.64770677, 0.59857517, 0.33225003, -1.14747663], [ 0.61866969, -0.08798693, 0.4250724 , 0.33225315, -1.15681626], [ 0.35099715, -0.60688728, 1.54697933, 0.72334161, 0.04613557], [-0.98299165, 0.05443274, 0.15989294, -1.20894816, 2.22336022]])#shuffle(a) 根据数组a的第一轴进行随机排列，改变数组a import numpy as npa = np.random.randint(1,100,(3,4))aarray([[50, 33, 40, 87], [37, 64, 35, 79], [41, 42, 11, 67]])np.random.shuffle(a) #不可赋值aarray([[41, 42, 11, 67], [37, 64, 35, 79], [50, 33, 40, 87]])#permutation(a) 根据数组a的第一轴进行随机排列， 但是不改变原数组，将生成新数组c = np.random.randint(100,200,(3,4))carray([[169, 144, 116, 192], [119, 131, 186, 190], [154, 159, 193, 189]])d = np.random.permutation(c)darray([[119, 131, 186, 190], [169, 144, 116, 192], [154, 159, 193, 189]])carray([[169, 144, 116, 192], [119, 131, 186, 190], [154, 159, 193, 189]])#choice(a[, size, replace, p]) 从一维数组a中以概率p抽取元素， 形成size形状新数组，replace表示是否可以重用元素，默认为False,choice默认可以重复。e = np.random.randint(100,200,(5,))earray([114, 136, 174, 158, 132])f = np.random.choice(e,(2,6))farray([[136, 114, 158, 158, 136, 174], [174, 114, 174, 132, 136, 158]])#把replace设定为False则随机选取的元素不能重复g = np.random.choice(e,(2,2),replace=False) #(2,2)2*2必须比e的个数少garray([[136, 114], [132, 158]])#uniform(low, high, size) 产生均匀分布的数组，起始值为low，high为结束值，size为形状 h = np.random.uniform(1,5,(3))harray([4.37271996, 1.96223774, 4.5393332 ])#normal(loc, scale, size) 产生正态分布的数组， loc为均值，scale为标准差，size为形状 i = np.random.normal(10,5,(3,4)) #均值是10，方差是5iarray([[ 6.25376239, 12.70219689, 9.66993908, 20.41170146], [ 8.09375048, 10.12743271, 3.93302745, 3.43204455], [ 8.02339524, 7.56522517, 4.25262042, 8.27390636]])#poisson(lam, size) 产生泊松分布的数组， lam随机事件发生概率，size为形状j = np.random.poisson(3,(2,5))jarray([[5, 4, 4, 3, 3], [2, 1, 2, 5, 1]]) 数组的类型转换1arr.astype() 栗子: 1234567891011121314151617181920212223242526272829303132333435#将整数转为浮点数In [8]: arr = np.array([1,2,3,4,5])In [9]: arrOut[9]: array([1, 2, 3, 4, 5])In [10]: arr.dtypeOut[10]: dtype('int64')In [11]: float_arr = arr.astype(np.float64)In [12]: float_arr.dtypeOut[12]: dtype('float64')In [13]: float_arrOut[13]: array([1., 2., 3., 4., 5.])#将浮点数转化为整数(去除了小数部分)In [14]: arr = np.array([1.23,3.21,4.32,5.67775])In [15]: arr.dtypeOut[15]: dtype('float64')In [16]: arr.astype(np.int32)Out[16]: array([1, 3, 4, 5], dtype=int32)#将字符串转为数值In [17]: arr = np.array(['1.2','2.34',' 4.3242'])In [18]: arrOut[18]: array(['1.2', '2.34', '4.3242'], dtype='&lt;U6')In [19]: arr.astype(float)Out[19]: array([1.2 , 2.34 , 4.3242]) 数组的索引/切片/级联/切分/副本123456切片同listnp.hstack:水平级联np.vstack :垂直级联np.splitnp.vsplit :垂直切分np.hsplit :水平切分 栗子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153#索引In [39]: import numpy as npIn [40]: nd1 = np.array([1,3,5,7,9,0])In [41]: nd1[2]Out[41]: 5In [42]: nd1[-1]Out[42]: 0In [43]: nd1[2]Out[43]: 5In [44]: nd1[2] = 100In [45]: nd1[-1] = 1024#切片In [46]: nd1Out[46]: array([ 1, 3, 100, 7, 9, 1024])In [47]: nd1[0:2]Out[47]: array([1, 3])In [48]: nd1[-3:-1]Out[48]: array([7, 9])In [49]: nd1[-3:]Out[49]: array([ 7, 9, 1024])In [50]: nd1Out[50]: array([ 1, 3, 100, 7, 9, 1024])In [51]: nd1[::-1]Out[51]: array([1024, 9, 7, 100, 3, 1])#np.hstack与np.vstack,水平级联与垂直级联,处理自己，进行维度的变更In [52]: nd2 = np.vstack(nd1)In [53]: nd2Out[53]: array([[ 1], [ 3], [ 100], [ 7], [ 9], [1024]])In [54]: np.hstack(nd2)Out[54]: array([ 1, 3, 100, 7, 9, 1024])In [55]: nd3 = np.random.randint(0,10,size = (4,3,5))In [56]: nd3Out[56]: array([[[6, 2, 1, 6, 9], [6, 6, 7, 7, 7], [9, 2, 5, 6, 8]], [[4, 3, 6, 3, 5], [4, 6, 0, 1, 0], [1, 9, 3, 2, 8]], [[8, 2, 9, 2, 6], [4, 6, 2, 8, 6], [5, 9, 3, 4, 3]], [[2, 0, 4, 5, 3], [8, 2, 0, 9, 1], [5, 9, 8, 6, 2]]])In [57]: np.hstack(nd3)Out[57]: array([[6, 2, 1, 6, 9, 4, 3, 6, 3, 5, 8, 2, 9, 2, 6, 2, 0, 4, 5, 3], [6, 6, 7, 7, 7, 4, 6, 0, 1, 0, 4, 6, 2, 8, 6, 8, 2, 0, 9, 1], [9, 2, 5, 6, 8, 1, 9, 3, 2, 8, 5, 9, 3, 4, 3, 5, 9, 8, 6, 2]])In [58]: nd3.shapeOut[58]: (4, 3, 5)#与级联类似，三个函数完成切分工作：np.split,np.vsplit,np.hsplitIn [59]: np.split(nd3,4)Out[59]: [array([[[6, 2, 1, 6, 9], [6, 6, 7, 7, 7], [9, 2, 5, 6, 8]]]), array([[[4, 3, 6, 3, 5], [4, 6, 0, 1, 0], [1, 9, 3, 2, 8]]]), array([[[8, 2, 9, 2, 6], [4, 6, 2, 8, 6], [5, 9, 3, 4, 3]]]), array([[[2, 0, 4, 5, 3], [8, 2, 0, 9, 1], [5, 9, 8, 6, 2]]])]In [60]: np.split(nd3,[1,2])Out[60]: [array([[[6, 2, 1, 6, 9], [6, 6, 7, 7, 7], [9, 2, 5, 6, 8]]]), array([[[4, 3, 6, 3, 5], [4, 6, 0, 1, 0], [1, 9, 3, 2, 8]]]), array([[[8, 2, 9, 2, 6], [4, 6, 2, 8, 6], [5, 9, 3, 4, 3]], [[2, 0, 4, 5, 3], [8, 2, 0, 9, 1], [5, 9, 8, 6, 2]]])]In [61]: nd4 = np.random.randint(0,100,size = (4,5))In [62]: nd4Out[62]: array([[72, 16, 25, 8, 21], [60, 0, 22, 74, 22], [58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])In [63]: np.hsplit(nd4,[1,2])Out[63]: [array([[72], [60], [58], [99]]), array([[16], [ 0], [74], [38]]), array([[25, 8, 21], [22, 74, 22], [48, 69, 78], [18, 84, 47]])]In [64]: np.vsplit(nd4,[1,2])Out[64]: [array([[72, 16, 25, 8, 21]]), array([[60, 0, 22, 74, 22]]), array([[58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])]In [65]: np.split(nd4,[1,2],axis=0)Out[65]: [array([[72, 16, 25, 8, 21]]), array([[60, 0, 22, 74, 22]]), array([[58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])]#创建副本,和原来数组地址一样In [66]: nd5 = nd4.copy()In [68]: id(nd4)Out[68]: 140512145734352In [69]: id(nd5)Out[69]: 140512145799568 数组的维度变换1234567.reshape(shape) ： 不改变数组元素，返回一个shape形状的数组，原数组不变.resize(shape) ： 与.reshape()功能一致，但修改原数组.swapaxes(ax1,ax2) ： 将数组n个维度中两个维度进行调换，不改变原数组.flatten() ： 对数组进行降维，返回折叠后的一维数组，原数组不变 栗子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344#reshape(shape) 不改变数组元素，返回一个shape形状的数组，原数组不变import numpy as npa = np.arange(20)a.reshape([5,4])array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]])a #a还是原来的aarray([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])#resize(shape) 与.reshape()功能一致，但修改原数组a.resize([4,5])a #a为a.resize后的数组array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]])#swapaxes(ax1,ax2) 将数组n个维度中两个维度进行调换，不改变原数组a.swapaxes(1,0) #将a的维度转换,由原来的4行5列变为5行4列array([[ 0, 5, 10, 15], [ 1, 6, 11, 16], [ 2, 7, 12, 17], [ 3, 8, 13, 18], [ 4, 9, 14, 19]])#flatten() 对数组进行降维，返回折叠后的一维数组，原数组不变a.flatten() array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])a #不改变原来的a数组array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14], [15, 16, 17, 18, 19]])b = a.flatten() #可赋值barray([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]) 数组的运算12345678910111213np.abs(a) np.fabs(a) : 取各元素的绝对值 np.sqrt(a) : 计算各元素的平方根 np.square(a): 计算各元素的平方 np.log(a) np.log10(a) np.log2(a) : 计算各元素的自然对数、10、2为底的对数 np.ceil(a) np.floor(a) : 计算各元素的ceiling 值， floor值（ceiling向上取整，floor向下取整） np.rint(a) : 各元素 四舍五入 np.modf(a) : 将数组各元素的小数和整数部分以两个独立数组形式返回 np.exp(a) : 计算各元素的指数值 np.sign(a) : 计算各元素的符号值 1（+），0，-1（-） np.maximum(a, b) np.fmax() : 比较（或者计算）元素级的最大值 np.minimum(a, b) np.fmin() : 取最小值 np.mod(a, b) : 元素级的模运算 np.copysign(a, b) : 将b中各元素的符号赋值给数组a的对应元素 数组的统计函数123456789101112131415sum(a, axis = None) : 依给定轴axis计算数组a相关元素之和，axis为整数或者元组 mean(a, axis = None) : 同理，计算平均值 average(a, axis =None, weights=None) : 依给定轴axis计算数组a相关元素的加权平均值 std（a, axis = None） ：同理，计算标准差 var（a, axis = None）: 计算方差 eg： np.mean(a, axis =1) ： 对数组a的第二维度的数据进行求平均 a = np.arange(15).reshape(3, 5) np.average(a, axis =0, weights =[10, 5, 1]) : 对a第一各维度加权求平均，weights中为权重，注意要和a的第一维匹配min(a) max(a) : 计算数组a的最小值和最大值 argmin(a) argmax(a) : 计算数组a的最小、最大值的下标（注：是一维的下标） unravel_index(index, shape) : 根据shape将一维下标index转成多维下标 ptp(a) : 计算数组a最大值和最小值的差 median(a) : 计算数组a中元素的中位数（中值） np.argmax(a) –&gt; 0 np.unravel_index( np.argmax(a), a.shape) –&gt; (0,0) 数组的any,all,where栗子: 1234567891011121314151617181920212223242526272829303132In [80]: a = np.array([1,2,3])In [81]: b = np.array([1,2,1])#any()任意个相等返回TrueIn [86]: (a == b).any()Out[86]: True#all()全部个相等返回TrueIn [87]: (a == b).all()Out[87]: False#三个参数numpy.where(condition，x，y)：满足condition条件，输出x，不满足输出yIn [90]: np.where([[True, False], [True, True]], ...: [[1, 2], [3, 4]], ...: [[9, 8], [7, 6]]) ...: #False的时候,x不满足条件,所以输出y 8 Out[90]: array([[1, 8], [3, 4]])#一个参数numpy.where(array):输出array中‘真’值的坐标（‘真‘也可以理解为非零）In [91]: np.where([[0, 1], [1, 0]])Out[91]: (array([0, 1]), array([1, 0]))In [92]: x=np.array([[0,1,2],[3,4,5],[6,7,8]])In [93]: np.where(x)#0为假所以不输出,从坐标(0,1)开始Out[93]: (array([0, 0, 1, 1, 1, 2, 2, 2]), array([1, 2, 0, 1, 2, 0, 1, 2])) 数组的梯度函数1np.gradient(f) : 计算数组f中元素的梯度，当f为多维时，返回每个维度梯度 扩展小知识:梯度 1连续值之间的变化率，即斜率(求导) 栗子: 1234567891011121314151617181920212223242526In [1]: import numpy as npIn [2]: a = np.random.randint(1,50,(6))In [3]: aOut[3]: array([17, 37, 23, 36, 22, 44])In [4]: np.gradient(a)Out[4]: array([20. , 3. , -0.5, -0.5, 4. , 22. ])In [5]: b = np.random.randint(1,50,(3,6))In [6]: bOut[6]: array([[22, 36, 37, 11, 33, 48], [16, 19, 24, 39, 37, 19], [28, 20, 47, 15, 24, 36]])In [7]: np.gradient(b)Out[7]: [array([[ -6. , -17. , -13. , 28. , 4. , -29. ], [ 3. , -8. , 5. , 2. , -4.5, -6. ], [ 12. , 1. , 23. , -24. , -13. , 17. ]]), array([[ 14. , 7.5, -12.5, -2. , 18.5, 15. ], [ 3. , 4. , 10. , 6.5, -10. , -18. ], [ -8. , 9.5, -2.5, -11.5, 10.5, 12. ]])] 矩阵操作栗子: 12345678910111213141516171819202122232425262728293031323334353637In [94]: nd4Out[94]: array([[72, 16, 25, 8, 21], [60, 0, 22, 74, 22], [58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])#加,每个数加5In [95]: nd4+5Out[95]: array([[ 77, 21, 30, 13, 26], [ 65, 5, 27, 79, 27], [ 63, 79, 53, 74, 83], [104, 43, 23, 89, 52]])#乘,每个数乘2In [96]: nd4*2Out[96]: array([[144, 32, 50, 16, 42], [120, 0, 44, 148, 44], [116, 148, 96, 138, 156], [198, 76, 36, 168, 94]])In [97]: nd1 = np.array([[2,3],[1,6]])In [98]: nd2 = np.array([[-1,2],[2,9]])#两个矩阵相乘,每个对应位相乘In [99]: nd1*nd2Out[99]: array([[-2, 6], [ 2, 54]])#矩阵积In [100]: np.dot(nd1,nd2)Out[100]: array([[ 4, 31], [11, 56]]) 数组的广播机制 ndarray广播机制的两条规则 规则一：为缺失的维度补1规则二：假定缺失元素用已有值填充栗子: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 广播机制的前提，维度必须有一维对应In [101]: nd4Out[101]: array([[72, 16, 25, 8, 21], [60, 0, 22, 74, 22], [58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])In [102]: nd3 = np.array([1,2,5,8,4])In [103]: nd4+nd3Out[103]: array([[ 73, 18, 30, 16, 25], [ 61, 2, 27, 82, 26], [ 59, 76, 53, 77, 82], [100, 40, 23, 92, 51]])In [104]: nd5 = np.array([-2,3.14,7.3,5.6])In [105]: nd4Out[105]: array([[72, 16, 25, 8, 21], [60, 0, 22, 74, 22], [58, 74, 48, 69, 78], [99, 38, 18, 84, 47]])In [106]: nd5 = np.random.randint(0,10,size = (4,1))In [107]: nd5Out[107]: array([[0], [0], [5], [2]])In [108]: nd4+nd5Out[108]: array([[ 72, 16, 25, 8, 21], [ 60, 0, 22, 74, 22], [ 63, 79, 53, 74, 83], [101, 40, 20, 86, 49]])In [109]: nd3Out[109]: array([1, 2, 5, 8, 4])In [110]: index = np.array([0,0,0,1,2,4,4,4,3])In [111]: nd3[index]Out[111]: array([1, 1, 1, 2, 5, 4, 4, 4, 8]) 随机创建图片12345import matplotlib.pyplot as plt import numpy as nppic = np.random.randint(0,200,(100,200,3))plt.imshow(pic)pic]]></content>
      <categories>
        <category>Numpy</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas连接mysql数据库]]></title>
    <url>%2F2018%2F08%2F17%2Fpandas%E8%BF%9E%E6%8E%A5mysql%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[安装 123pip install sqlalchemypip install pymysqlpip install pandas 导入包 12import pandas as pdfrom sqlalchemy import create_engine 连接数据库 1engine = create_engine('mysql+pymysql://用户名(一般为root):密码@localhost/数据库名') 直接读取数据 1data= pd.read_sql_table('表名',engine) 使用with,我们需要try,except,finally，做异常判断，并且文件最终不管遇到什么情况，都要执行finally f.close()关闭文件，with方法帮我们实现了finally中f.close 123​with engine.connect() as conn, conn.begin(): data = pd.read_sql_table('表名', conn)data 向数据库中插入数据 12df = pd.read_XXX('文件路径').head(10)df.to_sql('表名',engine,if_exists='append') 查看df信息 1df.info() 导出csv数据 1df.to_csv('/home/shanghaimei/Desktop/name.csv')]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Flask,Tornado创建]]></title>
    <url>%2F2018%2F08%2F16%2FFlask-Tornado%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617import tornado.ioloopimport tornado.webclass MainHandler(tornado.web.RequestHandler): def get(self): self.write("Hello world")def make_app(): return tornado.web.Application([(r"/", MainHandler)])if __name__ == "__main__": app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() 123456789101112131415from flask import Flaskapp = Flask(__name__)@app.route('/')def index(): return '&lt;h1&gt;Hello world&lt;/h1&gt;'@app.route('/user/&lt;name&gt;')def user(name): return '&lt;h1&gt;Hello, %s!&lt;/h1&gt;' % nameif __name__ == '__main__': app.run(host='0.0.0.0',port=5000,debug=True)]]></content>
      <categories>
        <category>web</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Telegram Client 开发]]></title>
    <url>%2F2018%2F08%2F16%2F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[可查阅telegram文档安装 1pip3 install --upgrade telethon 到https://my.telegram.org/用手机号登录这个网址申请api申请成功后保存好api_id和api_hash连接客户端 12345678910111213from telethon import TelegramClient, syncimport socks# Use your own values hereapi_id = 12345api_hash = '0123456789abcdef0123456789abcdef'client = TelegramClient('some_name' api_id, api_hash， proxy=(socks.SOCKS5, 'localhost', 4444) #代理设置).start()#此处的some_name是一个随便起的名称，第一次运行会让你输入手机号和验证码，之后会生成一个some_name.session的文件，再次运行的时候就不需要反复输入手机号验证码了myself = client.get_me()print(myself) #测试是否连接 引入的包 123456789from telethon import TelegramClient, sync,eventsimport loggingimport randomimport asyncioimport telethonfrom telethon.tl.types import PeerUser, PeerChat, PeerChannel,UpdateNewChannelMessagefrom telethon.tl.functions.messages import SendMessageRequestfrom telethon.tl import types, functionsfrom telethon import utils 连接 1234567api_id = 12345api_hash = '0123456789abcdef0123456789abcdef'client = TelegramClient('some_name' api_id, api_hash， proxy=(socks.SOCKS5, 'localhost', 4444) #代理设置).start() 给自己发送一条消息/文件 12client.send_message('me', 'Hello! Talking to you from Telethon')client.send_file('me', '/home/shanghaimei/Pictures/images.png') 获取自己发送的上一条信息 12messages = client.get_messages('me')#可更改用户名print(messages[0].text) 可以自定义聊天 123456@client.on(events.NewMessage)async def my_event_handler(event): if 'hello' in event.raw_text: await event.reply('hi!') if 'what' and 'name' in event.raw_text: await event.reply('Haimei_bot,Thanks!') 某个人的信息 1234peer = client.get_input_entity('@HuingZM')#可更换用户名peer = utils.get_input_peer(peer)print(peer)打印信息#InputPeerUser(user_id=1234556, access_hash=-5728264861981944) 给特定的人和频道发送信息 123result = client(SendMessageRequest('HuingZM', 'Hello there!'))result = client(SendMessageRequest(PeerChannel(1182116619), 'Hello there!'))print(result) 打印群信息 123 dialogs = client.get_dialogs()# 打印群信息 print(client.get_entity("@hello")) #可更换群组名 打印频道信息 12my_channel = client.get_entity(dialog.title)print(my_channel) 获取全部的聊天信息 12for message in client.iter_messages(1182116619): print(message) 判断列表信息 12345678910111213141516171819202122for dialog in client.iter_dialogs(): friend_info = client.get_entity(dialog.title) #dialog.title为first_name if type(friend_info) is not telethon.tl.types.User: channel_id = friend_info.id channel_title = friend_info.title channel_username = friend_info.username dict_channel_info = &#123;"channel_id":channel_id,"channel_title":channel_title,"channel_username":channel_username&#125; print(dialog.title,"这是一个频道",dict_channel_info) else: if friend_info.bot is False: user_id = friend_info.id user_name = friend_info.username is_bot = friend_info.bot user_phone = friend_info.phone dict_user_info = &#123;'user_id':user_id,'user_name':user_name,'user_phone':user_phone,'is_bot':is_bot&#125; print(dialog.title,"这是一个用户",dict_user_info) else: bot_id = friend_info.id bot_name = friend_info.username is_bot = friend_info.bot dict_bot_info = &#123;'bot_id':bot_id,'bot_name':bot_name,'is_bot':is_bot&#125; print(dialog.title,'这是一个机器人',dict_bot_info) 获取频道成员信息 1234567891011121314151617from telethon.tl.functions.channels import GetParticipantsRequestfrom telethon.tl.types import ChannelParticipantsSearchfrom time import sleepoffset = 0limit = 100all_participants = []while True: participants = client(GetParticipantsRequest( 1387666944, ChannelParticipantsSearch(''), offset, limit, hash=0 )) if not participants.users: break all_participants.extend(participants.users) for par in all_participants: print(par) 邀请人进群组 123456from telethon.tl.functions.messages import AddChatUserRequestclient(AddChatUserRequest( chat_id = -269442445 , #chat_id user_id = 585015279 , #被邀请人id fwd_limit=10 # Allow the user to see the 10 last messages)) 邀请人进频道 12345from telethon.tl.functions.channels import InviteToChannelRequestclient(InviteToChannelRequest( channel=1182116619, #频道id users = ['HuingZM'],#列表格式的username )) 获取频道成员信息并将成员加入自己的群组或频道,并加入欢迎语 123456789101112131415161718192021for dialog in client.iter_dialogs(): friend_info = client.get_entity(dialog.title) #dialog.title为first_name if type(friend_info) is not telethon.tl.types.User: channel_id = friend_info.id channel_title = friend_info.title channel_username = friend_info.username dict_channel_info = &#123;"channel_id":channel_id,"channel_title":channel_title,"channel_username":channel_username&#125; # print(dialog.title,"这是一个频道",dict_channel_info) channel = client.get_entity(PeerChannel(channel_id)) # 根据群组id获取群组对 responses = client.iter_participants(channel, aggressive=True) # 获取群组所有用户信息 for response in responses: if response.username is not None: d = &#123;'id':response.id,'username':response.username&#125; print(d) time.sleep(2) client(InviteToChannelRequest( channel=1219921340, users = [d.get('username')], )) client.send_message(1219921340,'''✨Welcome to &lt;a href="https://t.me/haimei_group"&gt;BiBi's group&lt;/a&gt; chat &#123;&#125; !'''.format(d.get('username')) ,parse_mode="html") time.sleep(2) ＃防止出现UserPrivacyRestrictedError 转发信息 1234 messages = client.get_messages('china_BiBi')#括号参数为来源频道username，因为要获取信息id mes_id = messages[0].id client.forward_messages(1219921340,mes_id,1182116619)#第一个参数为目标频道id，第二个信息id,第三个来源频道id 实时转发信息 12345678messages = client.get_messages('china_BiBi')mes_id_1 = messages[0].idwhile True: messages = client.get_messages('china_BiBi') mes_id = messages[0].id if mes_id != mes_id_1: client.forward_messages(1219921340,mes_id,1182116619) mes_id_1 = mes_id]]></content>
      <categories>
        <category>telegram</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[win下安装mysql报错发生系统错误2]]></title>
    <url>%2F2018%2F08%2F09%2F2%2F</url>
    <content type="text"><![CDATA[以管理员身份打开 1234567891011121314151617181920212223242526272829303132C:\WINDOWS\system32&gt;net start mysql发生系统错误 2。系统找不到指定的文件。C:\WINDOWS\system32&gt;mysqld -removeService successfully removed.C:\WINDOWS\system32&gt;mysqld --installService successfully installed.C:\WINDOWS\system32&gt;net start mysqlMySQL 服务正在启动 ....MySQL 服务已经启动成功。C:\WINDOWS\system32&gt;mysql -u root -pEnter password:Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 8.0.16 MySQL Community Server - GPLCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[数据库默认端口号]]></title>
    <url>%2F2018%2F08%2F07%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%BB%98%E8%AE%A4%E7%AB%AF%E5%8F%A3%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[关系型数据库 Oracle: 1521SQL Server: 1433MySQL: 3306pointbase: 9092DB2: 5000PostgreSQL: 5432非关系型数据库 MongoDB: 27017Redis: 6379memcached: 11211]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python连接mysql]]></title>
    <url>%2F2018%2F08%2F04%2Fpython%E8%BF%9E%E6%8E%A5mysql%2F</url>
    <content type="text"><![CDATA[启动mysqlnetstat -apn | grep mysql用mysql先创建一张表tele 12create table `tele`( `id` int(64) auto_increment primary key, `user_id` int(20) not null, `user_name` varchar(50) not null) engine=INNODB default charset=utf8; 连接pip install pymysql 12345678910111213141516171819import pymysqlconn = pymysql.connect(host='127.0.0.1', #本地 port=3306,#端口号 user='root', #用户名 password='123456', #密码 db='telegram', #数据库名称 charset='utf8' #设置字符集)cursor = conn.cursor() #获取操作游标 cursor.execute("truncate table tele") #可写sql语句 ,先清空表teletry: sql = "insert into tele(user_id, user_name) values('%s','%s')"%(user_id,user_name)#往表tele中插入数据 cursor.execute(sql) conn.commit() #提交到数据库执行except: conn.rollback() #发生错误回滚cursor.close() #关闭游标conn.close() # 关闭数据库连接 在数据库中查看数据 1234567mysql -u root -pshow databases; #查看所有数据库use 数据库名;show tables; #查看数据库中的所有表select * from 表名; #查看所有数据信息select count(*) from 表名; #查看数据条数SELECT COUNT(0) AS all_count FROM(select distinct 字段名称 from 表名) c; #查看不重复的数据 python查找数据 12345678910111213141516import pymysqlconn = pymysql.connect(host='127.0.0.1', port=3306, user='root', password='123456', db='telegram', charset='utf8')cursor = conn.cursor()sql = "select user_id from tele2"cursor.execute(sql)data = cursor.fetchall() #所有for i in data: print(i[0])cursor.close()conn.close(]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python连接redis和mongo数据库]]></title>
    <url>%2F2018%2F08%2F03%2Fpython%E8%BF%9E%E6%8E%A5redis%E5%92%8Cmongo%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[python连接redis 1234567import redisimport jsonr = redis.StrictRedis('localhost',6379,decode_responses=True)key = r.keys()for value in r.sscan_iter('info'): value = json.loads(value).get('name') print(value) python连接mongodb 123456import pymongoclient = pymongo.MongoClient(host = 'localhost',port = 27017)db = client.user #创建user数据库my_set = db.students #创建students集合result = my_set.insert([&#123;"name":"lingling","age":20,"phone":"13521386027"&#125;,&#123;"name":"Daming","age":15,"phone":"13521385024"&#125;])print(result)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis，mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb命令]]></title>
    <url>%2F2018%2F07%2F28%2FMongodb%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1234567891011mongo 启动数据库show dbs 查看数据库use 数据库名 切换到当前数据库db 查看当前数据库名称show collections 查看集合db.集合名.find() 查看所有数据db.集合名.drop() 删除集合db.dropDatabase() 删除当前数据库import datetime在Python中插入时间db.集合名.insert("date":datetime.datetime.now()) Python操作MongoDB一 安装 pymongo 123pip install pymongo导入 MongoClientfrom pymongo import MongoClient 二 链接MongoDB数据库 12MongoDB端口号:27017con= MongoClient("localhost"[,port=27017]) 三 选择数据库三 选择数据库 1db = con.数据库名 四 INSERT 数据的插入 1234567891011121314(1) 插入一条数据db.collection.insert(字典)插入成功:返回ID(2) 插入多条db.collection.insert([&#123;&#125;,&#123;&#125;])插入成功:返回ID的列表[ObjectId('5a1642c4b96166349c2963eb'), ObjectId('5a1642c4b96166349c2963ec')](3) 3.2以上的插入函数db.collection.insert_one() 插入一条数据db.collection.insert_many() 插入多条数据插入成功:返回obj(4) 3.2以上获取插入的idresultObj.inserted_id 获取插入一条的IDresultObj.inserted_ids 获取插入多条的ID 五 find 查询 123456789101112131415161718192021222324(1) find 查询db.collection.find()返回的是游标对象 使用next() 方法 进行取值(2) 按照id来进行查询#导入 objectid函数from bson.objectid import ObjectIddb.user.find(&#123;"_id" : ObjectId("5a152c31fa08a5e7ad2ad094")&#125;)(3) 模糊查询1. $regex2. import re re.compile()data = db.user.find(&#123;"name":&#123;"$regex":"五"&#125;&#125;)data = db.user.find(&#123;"name":re.compile("五")&#125;)注意 当匹配类型为 不是字符串的类型的时候 匹配不出来data = db.user.find(&#123;"age":re.compile("30")&#125;)data = db.user.find(&#123;"age":&#123;"$regex":"3"&#125;&#125;)(4) sort 排序sort(key,1) 升序sort(key,-1) 降序(5) limit 取值limit(num)(6) skip 跳过db.user.find().skip(num)db.user.find().skip(num).limit(num)db.user.find().sort(key,1/-1).skip(num).limit(num) 六 update 修改 1234567891011121314151617181920212223242526(1) db.collection.update(条件,更改后)# data = db.user.update(&#123;"name":"潘金莲"&#125;,&#123;"$inc":&#123;"age":2&#125;&#125;) #累加修改# data = db.user.update(&#123;"name":"潘金莲"&#125;,&#123;"$set":&#123;"age":2&#125;&#125;) #直接修改更改成功 返回 数据:&#123;'n': 1, 'nModified': 1, 'ok': 1.0, 'updatedExisting': True&#125;(2) update_one()修改一条数据db.collection.update_one()# data = db.user.update_one(&#123;"name":"王五"&#125;,&#123;"$set":&#123;"age":20&#125;&#125;)(3) update_many() 修改多条数据db.collection.update_many()data = db.user.update_one(&#123;"name":"王五"&#125;,&#123;"$set":&#123;"age":20&#125;&#125;)(4) update_one 和 update_many 返回匹配条数和修改的条数result.matched_countresult.modified_count注意:返回匹配条数返回修改的条数#修改多条当修改的数据 已经被修改过了 再次运行 不会再次进行修改参数很重要！！！update(查询条件, 更改后的数据, upsert, multi);upsert(默认为False)：（1）upsert = True 按条件找到数据更新，找不到insert一条新数据（2）upsert = False 按条件找到数据更新，找不到不做操作multi(默认为false):（1）multi = True 修改所有符合条件的数据（2）multi = False 只修改第一条符合条件的数据 七 remove 删除 1234(1) remove 匹配到的全部删除db.collection.remove(&#123;条件&#125;)(2) delete_one 删除一条db.collection.delete_one() 八 关闭数据库链接 1con.close()]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python字符串列表小知识]]></title>
    <url>%2F2018%2F07%2F16%2Fpython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%97%E8%A1%A8%E5%B0%8F%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[去除列表中的空字符串 12345list = ['','lingling','','','Daming']mylist = [x for x in list if x != '']print(mylist)#打印结果#['lingling', 'Daming'] 列表中的字符串拼接 1234567list = ['','lingling ','','',' Daming']mylist =''.join(list)print(mylist)print(type(mylist))#打印结果#lingling Daming#&lt;class 'str'&gt; 字符串中去除空格（例子中mylist为str类型，上述已打印类型） 12345678list = ['','lingling ','','',' Daming']mylist =''.join(list)mystr = mylist.replace(' ','')print(mystr)print(type(mystr))#打印结果#linglingDaming#&lt;class 'str'&gt; 分割字符串（mystr为list类型，结果为上述类型中第一个，可用第一个方法去除空字符串） 1234567str = "\nlingling\nDaming"mystr = str.split('\n')print(mystr)print(type(mystr))#打印结果#['', 'lingling', 'Daming']#&lt;class 'list'&gt; 小栗子 12345678910111213141516lislist = ['\n Until 08 May - ', '47%', '\n 09 May - 08 June - ', '37%', '\n 26 June - 09 July - ', '27%', '\n 10 - 23 July - ', '17%', '\n 24 July - 06 August - ', '7%']mylist = (''.join(list)).split('\n')newlist = [x.strip(' ') for x in mylist if x != '']print(newlist)#打印结果：['Until 08 May - 47%', '09 May - 08 June - 37%', '26 June - 09 July - 27%', '10 - 23 July - 17%', '24 July - 06 August - 7%'] 嵌套列表转化为字典 1234In [36]: l = [['k1','v1'],['k2','v2'],['k3','v3']]In [37]: dict(l)Out[37]: &#123;'k1': 'v1', 'k2': 'v2', 'k3': 'v3'&#125; 小栗子 1234567891011date = [&#123;'start':'2018-1-1','end':'2018-2-2'&#125;,&#123;'start':'2018-3-1','end':'2018-5-2'&#125;]newdate = []for i in date: d = ("%s---%s")%(i['start'],i['end']) newdate.append(d) print(i['start'],i['end'])print(newdate)#打印结果：2018-1-1 2018-2-22018-3-1 2018-5-2['2018-1-1---2018-2-2', '2018-3-1---2018-5-2'] 小栗子 12345678910111213141516list1 = ['1','2','3','4']list2 = ['a','b','c','d']list3 = ['A','B','C','D']data = tuple(zip(list1,list2,list3))my_list = []my_dict = &#123;&#125;for x,y,z in data: data = &#123;'name':x,'age':y,'sex':z&#125; my_list.append(data)my_dict.update(&#123;'info':my_list&#125;)print(my_dict)打印结果：&#123;'info': [&#123;'name': '1', 'age': 'a', 'sex': 'A'&#125;, &#123;'name': '2', 'age': 'b', 'sex': 'B'&#125;, &#123;'name': '3', 'age': 'c', 'sex': 'C'&#125;, &#123;'name': '4', 'age': 'd', 'sex': 'D'&#125;]&#125; 对源码制定规则(工作中) 1234teamsinfo = response.text.split("window.__INITIAL_STATE__=", 1)[1].split('team":')[1].split(',"token_for_sale')[0]item_1['teamsinfo'] = json.loads(teamsinfo)logo = response.text.split('image":')[1].split(',"datePublished')[0]item_1['logo'] = json.loads(logo)[0] 查看返回内容 12res = response.textprint(res)]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux命令使用]]></title>
    <url>%2F2018%2F06%2F11%2FLinux%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[ubuntu软件安装与卸载1234567891011121314151617apt-get install 下载sudo apt-get update 更新源sudo apt-get install package 安装包sudo apt-get remove package 删除包sudo apt-cache search package 搜索包sudo apt-cache show package 获取包的相关信息，如说明、大小、版本等sudo apt-get install package --reinstall 重新安装包sudo apt-get -f install 修复安装sudo apt-get remove package --purge 删除包，包括配置文件等sudo apt-get build-dep package 安装相关的编译环境sudo apt-get upgrade 更新已安装的包sudo apt-get dist-upgrade 升级系统sudo apt-cache depends package 了解使用该包依赖哪些包sudo apt-cache redepends package 查看该包被哪些包依赖sudo apt-get source package 下载该包的源代码sudo apt-get clean &amp;&amp; sudo apt-get autoclean 清理无用的包sudo apt-get check 检查是否有损坏的依赖 手动安装python环境12345678910111213sudo apt-get update sudo apt-get install software-properties-common sudo add-apt-repository ppa:jonathonf/python-3.6 sudo apt-get update sudo apt-get install python3.6 cd /usr/bin ls | grep python sudo rm python sudo ln -s python3.6m python sudo apt install python3-pip pip --version python pip install --upgrade pip pip --version sublime text 3解决中文输入123456789101112sudo apt-get update &amp;&amp; sudo apt-get upgradegit clone https://github.com/lyfeyaj/sublime-text-imfix.git(https://github.com/lyfeyaj/sublime-text-imfix.git)cd sublime-text-imfix./sublime-imfixsublime光标设置按住insert +shift 光标就由横线变成竖线了 虚拟环境virtualenv安装 123456789sudo apt install virtualenvsudo apt install virtualenvwrappermkdir ~/.virtualenvssudo vim ~/.bashrc 文件末尾添加（注意virtualenvwrapper.sh的路径可以用whereis virtualenvwrapper来寻找，进入目录后ls一下看看有没有virtualenvwrapper.sh这个文件）export WORKON_HOME=$HOME/.virtualenvssource /usr/local/bin/virtualenvwrapper.sh退出后执行source ~/.bashrc 创建 123456789查看版本号： virtualenv --version格式： mkvirtualenv 虚拟环境名称 （此环境是根据系统变量环境创建的，为py2）创建py3虚拟环境： 找到python3的路径 which python3 /usr/bin/python3 mkvirtualenv --python=/usr/bin/python3 虚拟环境名称 查看虚拟环境 1workon 两下tab键 进入虚拟环境 1workon 虚拟环境名称 退出虚拟环境 12deactivate记不住可deac tab自动补全退出 删除虚拟环境 1rmvirtualenv 虚拟环境名称 说明 1所有的虚拟环境，都位于/home/.virtualenvs目录下 终端启动Pycharm1终端进入文件的bin目录：运行./pycharm.sh linux下安装PhantomJS下载地址 1http://phantomjs.org/download.html 进入下载目录解压 1tar jxvf phantomjs-2.1.1-linux-x86_64.tar.bz2 移动 12sudo mv -f phantomjs /usr/bin/phantomjssudo ln -s /usr/bin/phantomjs /usr/local/bin/phantomjs Linux下远程连接服务器上传文件在Liunx下打开终端(都是在本地操作)远程连接服务器 1ssh root@ip地址 拷贝文件或者文件夹从本地上传到服务器 1scp -r /home/shanghaimei/Downloads/380/ root@ip地址:/home/zacks/work/ 从服务器下载到本地 1scp -r root@ip地址:/home/zacks/work/ico-1.0/download.html /home/shanghaimei/Desktop/ Linux命令解压打包1234567.tar解包：tar xvf FileName.tar打包：tar cvf FileName.tar DirName.gz解压：gunzip FileName.gz压缩：gzip FileName Linux打开pychaarm1终端进入文件的bin目录：运行./pycharm.sh]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装chromedriver]]></title>
    <url>%2F2018%2F06%2F10%2FLinux%E4%B8%8B%E5%AE%89%E8%A3%85chromedriver%2F</url>
    <content type="text"><![CDATA[12345678910111213在官网下载对应的版本https://sites.google.com/a/chromium.org/chromedriver/进入到下载目录unzip chromedriver_linux64.zip移动到相应目录sudo mv -f chromedriver /usr/local/bin/chromedriversudo ln -s /usr/local/bin/chromedriver /usr/bin/chromedriver测试是否成功from selenium import webdriver browser = webdriver.Chrome()]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python字典key替换]]></title>
    <url>%2F2018%2F06%2F09%2Fpython%E5%AD%97%E5%85%B8key%E6%9B%BF%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[123456coninfos = response.xpath('//*[@id="app"]/div[3]/div/div[2]/main/div[2]/div/div')datadict = &#123;"状态":"status","货币符号":"symbol","开始日期":"start_date","结束日期":"end_date","目标下限":"soft_cap","目标上限":"hard_cap","初始价格":"initial_price","代币数":"token_supply","募集金额":"collection_amount"&#125; for coninfo in coninfos: key = coninfo.xpath('./div[1]/text()').get() value = coninfo.xpath('./div[2]/text()').get() item[datadict[key]] = value]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Django返回API接口]]></title>
    <url>%2F2018%2F06%2F08%2F%E9%85%8D%E7%BD%AEDjango%E8%BF%94%E5%9B%9EAPI%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[1.settings.py中设置redis取数据 12345REDIS = &#123; 'host': '127.0.0.1', 'port': 6379, 'db': 0,&#125; 2.settings.py中添加创建的APP （ INSTALLED_APPS） 1234567891011INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', # 'rest_framework', # 'rest_framework_swagger', 'my_test',] 3.配置项目中的urls.py设置总路由（django版本不同，设置不同，可参考官网） 123456789101112from django.conf.urls import url,includefrom django.contrib import admin# from rest_framework.schemas import get_schema_view# from my_test.views import ReturnJson# from . import viewsurlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^', include("my_test.urls", namespace="my_test")), #版本1.11.4 # url(r'^index/',get_schema_view()), # url(r'^alldata/', ReturnJson.as_view()),] 4.在创建的app中编辑views.py,例取全部数据以json格式返回数据 12345678910111213141516171819#-*- coding:utf-8 -*-from django.shortcuts import renderfrom django.conf import settingsfrom django.core.cache import cache# from dss.Serializer import serializer# from rest_framework.views import APIViewfrom redis import Redisimport jsonfrom django.http import HttpResponse,HttpRequestrds = Redis(**settings.REDIS)def alldata(request): values = [] for value in rds.sscan_iter('chinadata'): value = value.decode('utf-8') val = json.loads(value) values.append(val) return HttpResponse(json.dumps(values),content_type="application/json;charset=utf-8") 按字段分类取数据 123456789101112131415def going(request): values = [] # key = rds.keys()[0] for value in rds.sscan_iter('chinadata'): # print(type(value)) #bytes value = value.decode('utf-8') # print(type(value)) # str val = json.loads(value) # print(type(val)) #dict status = val["status"] if val["status"] == '准备中': values.append(val) # print(type(values)) #list return HttpResponse(json.dumps(values,ensure_ascii=False),content_type="application/json;charset=utf-8") 5.设置APP中的urls.py， 1234567from django.conf.urls import urlfrom . import viewsurlpatterns = [ url(r'^alldata/$', views.alldata), url(r'^going/$',views.going),] 6.运行 1python manage.py runserver]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac快捷键和触控板使用]]></title>
    <url>%2F2018%2F06%2F05%2F%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%92%8C%E8%A7%A6%E6%8E%A7%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425cmd + 空格 打开Spotlight搜索cmd + shift + 3 截取全部屏幕cmd + shift + 4 截取所选屏幕区域，或按空格键捕捉一个窗口点击文件 + return 重命名cmd + N 新建文件夹点击废纸篓 + cmd + shift + del 清空废纸篓选中文件 + cmd + del 将文件移至废纸篓 cmd + F 搜索浏览器中 + cmd + W 关闭当前窗口 三个手指滑动 切换全屏两个手指在右边向里滑动，打开今天通知中心两个手指左右滑动 在页面之间轻扫三个手指向上轻扫 Mission Control三个手指向下轻扫 应用Expose捏拢拇指和其他三个手指 显示应用程序张开拇指和其他三个手指 显示桌面三个手指轻点 查找与数据检测器（字典）两个手指轻点 右击一个手指轻点 左击两个手指上下移动 网页上下滚动两个手指捏合 放大或者缩小两个手指轻点两下 智能缩放两个手指旋转 照片旋转]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-models定义属性]]></title>
    <url>%2F2018%2F06%2F04%2FDjango-models%E5%AE%9A%E4%B9%89%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[概述 ·django根据属性的类型确定以下信息 ·当前选择的数据库支持字段的类型 ·渲染管理表单时使用的默认html控件 ·在管理站点最低限度的验证 ·django会为表增加自动增长的主键列，每个模型只能有一个主键列，如果使用选项设置某属性为主键列后，则django不会再生成默认的主键列 ·属性命名限制 ·不能是python的保留关键字 ·由于django的查询方式，不允许使用连续的下划线 库 ·定义属性时，需要字段类型，字段类型被定义在django.db.models.fields目录下，为了方便使用，被导入到django.db.models中 ·使用方式 ·导入from django.db import models ·通过models.Field创建字段类型的对象，赋值给属性 逻辑删除 ·对于重要数据都做逻辑删除，不做物理删除，实现方法是定义isDelete属性，类型为BooleanField，默认值为False 字段类型 ·AutoField ·一个根据实际ID自动增长的IntegerField，通常不指定如果不指定，一个主键字段将自动添加到模型中 ·CharField(max_length=字符长度) ·字符串，默认的表单样式是 TextInput ·TextField ·大文本字段，一般超过4000使用，默认的表单控件是Textarea ·IntegerField ·整数 ·DecimalField(max_digits=None, decimal_places=None) ·使用python的Decimal实例表示的十进制浮点数 ·参数说明 ·DecimalField.max_digits ·位数总数 ·DecimalField.decimal_places ·小数点后的数字位数 ·FloatField ·用Python的float实例来表示的浮点数 ·BooleanField ·true/false 字段，此字段的默认表单控制是CheckboxInput ·NullBooleanField ·支持null、true、false三种值 ·DateField[auto_now=False, auto_now_add=False]) ·使用Python的datetime.date实例表示的日期 ·参数说明 ·DateField.auto_now ·每次保存对象时，自动设置该字段为当前时间，用于&quot;最后一次修改&quot;的时间戳，它总是使用当前日期，默认为false ·DateField.auto_now_add ·当对象第一次被创建时自动设置当前时间，用于创建的时间戳，它总是使用当前日期，默认为false ·说明 ·该字段默认对应的表单控件是一个TextInput. 在管理员站点添加了一个JavaScript写的日历控件，和一个“Today&quot;的快捷按钮，包含了一个额外的invalid_date错误消息键 ·注意 ·auto_now_add, auto_now, and default 这些设置是相互排斥的，他们之间的任何组合将会发生错误的结果 ·TimeField ·使用Python的datetime.time实例表示的时间，参数同DateField ·DateTimeField ·使用Python的datetime.datetime实例表示的日期和时间，参数同DateField ·FileField ·一个上传文件的字段 ·ImageField ·继承了FileField的所有属性和方法，但对上传的对象进行校验，确保它是个有效的image 字段选项 ·概述 ·通过字段选项，可以实现对字段的约束 ·在字段对象时通过关键字参数指定 ·null ·如果为True，Django 将空值以NULL 存储到数据库中，默认值是 False ·blanke ·如果为True，则该字段允许为空白，默认值是 False ·注意 ·null是数据库范畴的概念，blank是表单验证证范畴的 ·db_column ·字段的名称，如果未指定，则使用属性的名称 ·db_index ·若值为 True, 则在表中会为此字段创建索引 ·default ·默认值 ·primary_key ·若为 True, 则该字段会成为模型的主键字段 ·unique ·如果为 True, 这个字段在表中必须有唯一值 关系 ·分类 ·ForeignKey：一对多，将字段定义在多的端中 ·ManyToManyField：多对多，将字段定义在两端中 ·OneToOneField：一对一，将字段定义在任意一端中 ·用一访问多 ·格式 ·对象.模型类小写_set ·示例 grade.students_set ·用一访问一 ·格式 ·对象.模型类小写 ·示例 ·grade.students ·访问id ·格式 ·对象.属性_id ·示例 ·student.sgrade_id]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python创建Django项目流程]]></title>
    <url>%2F2018%2F06%2F03%2Fpython%E5%88%9B%E5%BB%BADjango%E9%A1%B9%E7%9B%AE%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.进入虚拟环境，查看当前django版本 12345workon 虚拟环境名称ipythonimport djangodjango.get_version()#返回"1.11.4" 2.创建项目 1django-admin.py startproject 项目名称 3.创建项目中的app 12cd 项目名称 python manage.py startapp app名称 4.运行项目 1python manage.py runserver 12345678June 01, 2018 - 09:21:18Django version 1.11.4, using settings 'test_interface.settings'Starting development server at http://127.0.0.1:8000/Quit the server with CONTROL-C.[01/Jun/2018 09:22:12] "GET / HTTP/1.1" 200 1716Not Found: /favicon.ico[01/Jun/2018 09:22:15] "GET /favicon.ico HTTP/1.1" 404 1970[01/Jun/2018 09:35:14] "GET / HTTP/1.1" 200 1716 5.访问Starting development server at http://127.0.0.1:8000/中的http://127.0.0.1:8000/ 6.项目完成！]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中把ISO-8859-1编码转化为UTF-8]]></title>
    <url>%2F2018%2F06%2F02%2Fpython%E4%B8%AD%E6%8A%8AISO-8859-1%E7%BC%96%E7%A0%81%E8%BD%AC%E5%8C%96%E4%B8%BAUTF-8%2F</url>
    <content type="text"><![CDATA[当我们爬取一些页面的中文信息时，会出现如下情况：爬取的中文编码格式不是UTF-8,无法正常显示，查看编码格式：编码格式为ISO-8859-1（长见识啦~）我们先定义一个这种编码的字符串：先编码后解码完整流程爬取内容变为中文 encode(编码)：按照某种规则将“文本”转换为“字节流”，unicode转化为str decode(解码)：将“字节流”按照某种规则转换成“文本”，str转化为unicode s.decode(‘ ‘)：运行会出错。因为python 3中的str类型对象有点像Python 2中的unicode， 而decode是将str转为unicode编码，所以str仅有一个encode方法，调用这个方法后将产生一个编码后的byte类型的字符。AttributeError: ‘str’ object has no attribute ‘decode’AttributeError: ‘bytes’ object has no attribute ‘encode’]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Scrapy创建scrapy爬虫项目]]></title>
    <url>%2F2018%2F06%2F01%2FScrapy%E5%88%9B%E5%BB%BAscrapy%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[1.在终端进入安装好依赖的虚拟环境，执行命令 1scrapy startproject 项目名称 提示进入 项目名称 并执行scrapy genspider example example.com 2.查看项目结构3.cd 进入项目名称 执行scrapy genspider 主爬虫文件名 爬虫基础的域名(主爬虫文件名不可与项目名重复，爬虫基础域名格式为xxx.com) 12cd chinadatascrapy genspider chinainfo zh.coinjinja.com 4.查看项目结构，在spiders文件夹中多出chinainfo.py的文件，此文件写主爬虫，name为刚才创建的主爬虫文件名。要引入文件夹中的items.py中的item类!!5.运行爬虫 1scrapy crawl 主爬虫文件名 6.将数据保存到本地文件 1保存数据: scrapy crawl 主爬虫文件名 -t 数据格式 -o 指定的文件 -a 设定请求爬虫数量 -L日志级别]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用git]]></title>
    <url>%2F2018%2F05%2F28%2FLinux%E4%B8%8B%E4%BD%BF%E7%94%A8git%2F</url>
    <content type="text"><![CDATA[安装 1sudo apt-get install git 配置 12git config --global user.name "git注册的用户名"git config --global user.email "git注册的邮箱" 生成密钥 12ssh-keygen -t rsa -C "git注册的邮箱"提示输入密码 GitHub上添加公有密钥 12345678910111213github上操作： 登陆GitHub官网 点击头像 下拉选择Settings点击进入 右栏选择SSH and GPG keys点击 会出现SSH KeysLinux系统下操作： 进入.ssh下面会有三个文件 id_rsa id_rsa.pub know_hosts cat id_rsa.pub 会出现一串公钥github上操作： 点击New SSH key添加到github（注意后面的邮箱要删掉） 验证密钥是否通过 1ssh -T git@github.com 测试 123456git clone https://github.com/...git status 查看状态git add 状态的连接选择要提交的修改文件（git add . 为全部提交）git commit -m "说明" （git commit -a 为提交全部，可省略git add）git push 上推git pull 下拉]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python连接firebase云数据库]]></title>
    <url>%2F2018%2F05%2F26%2Fpython%E8%BF%9E%E6%8E%A5firebase%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[1.创建项目，点击启用，测试 2.将 Firebase Admin SDK 添加到您的 Python 应用中 1pip install --upgrade firebase-admin 3.进入项目，左上设置用户和权限，点击服务账号，生成新的私钥json文件下载到本地，使用该文件初始化SDK 4.代码段 12345678910111213141516171819202122232425262728293031323334353637383940import firebase_adminfrom firebase_admin import credentialsfrom firebase_admin import firestore# Use a service accountcred = credentials.Certificate('json文件路径')firebase_admin.initialize_app(cred)db = firestore.client()#创建一个新集合和一个新文档doc_ref = db.collection(u'users').document(u'alovelace')doc_ref.set(&#123; u'first': u'Ada', u'last': u'Lovelace', u'born': 1815&#125;)#将另一个文档添加到 users 集合doc_ref = db.collection(u'users').document(u'aturing')doc_ref.set(&#123; u'first': u'Alan', u'middle': u'Mathison', u'last': u'Turing', u'born': 1912&#125;)#使用“get”方法来检索整个集合users_ref = db.collection(u'users')docs = users_ref.get()for doc in docs: print(u'&#123;&#125; =&gt; &#123;&#125;'.format(doc.id, doc.to_dict())) python连接redis测试 12345import redisr = redis.StrictRedis('localhost',6379，decode_responses=True)value = r.set('name','zhangsan')print(value)#返回True *连接redis，加上decode_responses=True，写入的键值对中的value为str类型，不加这个参数写入的则为字节类型。 案例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import firebase_adminfrom firebase_admin import credentialsfrom firebase_admin import firestoreimport redisimport jsonimport time# Use a service accountcred = credentials.Certificate('/home/shanghaimei/work/contents-9ab37-firebase-adminsdk-hopy8-318be1f4ab.json')firebase_admin.initialize_app(cred)r = redis.StrictRedis('localhost',6379,decode_responses=True)key = r.keys()[1]for value in r.sscan_iter('ICO'): startup_name = json.loads(value).get('startup_name') start_end_ico = json.loads(value).get('start_end_ico') hype_score = json.loads(value).get('hype_score') risk_score = json.loads(value).get('risk_score') raised= json.loads(value).get('raised') goal = json.loads(value).get('goal') # name = json.loads(value).get('name') share_link = json.loads(value).get('share_link') # ico_date = json.loads(value).get('ico_date') industry = json.loads(value).get('industry') description = json.loads(value).get('description') features = json.loads(value).get('features') # technical_details = json.loads(value).get('technical_details') product_type = json.loads(value).get('product_type') website = json.loads(value).get('website') db = firestore.client() time.sleep(2) doc_ref = db.collection(key).document(startup_name) doc_ref.set(&#123; u'startup_name': startup_name,#后面是for循环取出来的字段 u'start_end_ico':start_end_ico, u'hype_score':hype_score, u'risk_score':risk_score, u'raised':raised, u'goal':goal, # u'name':name, u'share_link':share_link, # u'ico_date':ico_date, u'industry':industry, u'description':description, u'features':features, # u'technical_details':technical_details, u'product_type':product_type, u'website':website &#125;) 小知识:json.dumps()：接收python类型的数据作为参数，返回了一个str对象的encodedjson（从python数据转换为json） json.loads()：接收json字符串，返回python类型的数据（从json字符串转换为python数据）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[xpath使用小技巧]]></title>
    <url>%2F2018%2F05%2F25%2Fxpath%E4%BD%BF%E7%94%A8%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[xpath获取A下所有的子链接: //A/child::*/@href xpath 使用单引号，使用双引号报语法错误 (如果外部使用单引号,内部就要使用双引号,反之使用单引号) li下或者p下包含strong标签或者其他的标签: //ul/li/descendant::text() //p/descendant::text() 如果一个div中包含多个class,选取其中一个的方法,用contains函数 //span[contains(@class,&quot;vote-post-up&quot;)]]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[redis外部连接设置]]></title>
    <url>%2F2018%2F05%2F24%2Fredis%E5%A4%96%E9%83%A8%E8%BF%9E%E6%8E%A5%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[1&gt;注释掉bind #bind 127.0.0.1 2&gt;默认不是守护进程方式运行，这里可以修改 daemonize no（一般设置为yes） 3&gt;禁用保护模式protected-mode no 也可以加bind ip 重启redis服务 sudo redis-server /etc/redis/redis.conf]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy命令]]></title>
    <url>%2F2018%2F05%2F23%2Fscrapy%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[查看是否成功scrapy settings --get=BOT_NAME 打印信息 scrapy crawl info scrapy crawl --help -o 将数据保存到指定文件 -t 指定数据的格式,支持的数据格式有xml,json,csv,pickle,marshal –logfile 存储错误日志的文件 -L 日志级别 –set 设置环境变量 保存数据: scrapy crawl university -t 数据格式 -o 指定的文件 -a 设定请求爬虫数量 -L日志级别 进入虚拟环境,运行以下命令 12345(scrapy) shanghaimei@shanghaimei:~$ scrapy shell "https://book.douban.com/"[s] shelp() Shell help (print this help)[s] view(response) View response in a browserIn [1]: 会发现返回403 1[s] response &lt;403 https://movie.douban.com&gt; 只要在命令上加请求头就正常返回了 1scrapy shell "https://movie.douban.com" -s USER_AGENT='Mozilla/5.0' 下面拿数据了,找打数据接口,执行 1234scrapy shell "https://movie.douban.com/j/search_subjects?type=tv&amp;tag=%E7%83%AD%E9%97%A8&amp;page_limit=50&amp;page_start=0" -s USER_AGENT='Mozilla/5.0'In [1]: view(response)Out[1]: True#返回一个txt的json数据文件]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
</search>
